# Run Performance Benchmark Workflow

API : POST /benchmark/run-workflow

## Steps for Running Performance Benchmark

### Step 1: Provide Basic Info

Give:
- Name
- Tags
- Description
- Concurrent requests
- Evaluation method: `configuration` or `dataset`

### Step 2: Evaluation Details

- If **evaluation method is "configuration"**: specify `max_input_tokens` and `max_output_tokens`
- If **evaluation method is "dataset"**: choose datasets from the list

### Step 3: Choose Cluster

Select the cluster where the benchmark should run.

### Step 4: Choose Nodes

Pick the specific nodes within the cluster.

### Step 5: Choose Model

Choose the model to run the benchmark.

#### Step 5.1: If Model is Cloud-Based

Select the cloud model credential.

### Step 6: Confirm Benchmark Details

User confirmation of all benchmark details.

### Step 7: Execution Option

Choose either:
- `Simulate` (currently not operational)
- `Run on cluster`

### Step 8: Deployment

Trigger deployment steps. If successful, workflow ends with a success step; otherwise, an error will be shown during deployment.

---

## Example JSON Payloads

### Step 1

<details>
<summary>Configuration method</summary>

```json
{
  "name": "test-111",
  "tags": [],
  "description": "test-111",
  "concurrent_requests": 50,
  "eval_with": "configuration",
  "workflow_total_steps": 9,
  "step_number": 1,
  "trigger_workflow": false
}
```
</details>

<details>
<summary>Dataset method</summary>

```json
{
  "name": "test-111",
  "tags": [],
  "description": "test-111",
  "concurrent_requests": 50,
  "eval_with": "dataset",
  "workflow_total_steps": 9,
  "step_number": 1,
  "trigger_workflow": false
}
```
</details>

---

### Step 2

<details>
<summary>Using Configuration</summary>

```json
{
  "name": "test-111",
  "tags": [],
  "description": "test-111",
  "concurrent_requests": 50,
  "eval_with": "configuration",
  "workflow_id": "dcfddf9b-5f07-47e9-8483-24f546bb7667",
  "step_number": 2,
  "trigger_workflow": false,
  "max_input_tokens": 50,
  "max_output_tokens": 100
}
```
</details>

<details>
<summary>Using Dataset</summary>

```json
{
  "name": "test-111",
  "tags": [],
  "description": "test-111",
  "concurrent_requests": 50,
  "eval_with": "dataset",
  "workflow_id": "dcfddf9b-5f07-47e9-8483-24f546bb7667",
  "step_number": 2,
  "trigger_workflow": false,
  "datset_ids": ["effddf9b-5f07-47e9-8483-24f546bb7667"]
}
```
</details>

---

### Step 3: Choose Cluster

```json
{
  "name": "test-111",
  "tags": [],
  "description": "test-111",
  "concurrent_requests": 50,
  "eval_with": "configuration",
  "workflow_id": "9e4aa5c6-d2df-42ab-8972-a954bd7f6485",
  "step_number": 3,
  "trigger_workflow": false,
  "cluster_id": "1fbb9c3c-4198-4e7e-8a1e-02b86041ea82"
}
```

---

### Step 4: Choose Nodes

Node json is response of GET node-metrics API

```json
{
  "name": "test-111",
  "tags": [],
  "description": "test-111",
  "concurrent_requests": 50,
  "eval_with": "configuration",
  "workflow_id": "9e4aa5c6-d2df-42ab-8972-a954bd7f6485",
  "step_number": 4,
  "trigger_workflow": false,
  "nodes": [
    {
      "hostname": "fl4u42",
      "status": "Ready",
      "devices": [
        {
          "name": "Intel(R) Xeon(R) Platinum 8480+",
          "type": "cpu",
          "device_info": {
            "num_virtual_cores": 224
          },
          "device_config": {
            "peak_fp16_TFLOPS": 329.00454400000007
          },
          "available_count": 8
        }
      ]
    }
  ]
}
```

---

### Step 5: Choose Model

```json
{
  "name": "test-111",
  "tags": [],
  "description": "test-111",
  "concurrent_requests": 50,
  "eval_with": "configuration",
  "workflow_id": "9e4aa5c6-d2df-42ab-8972-a954bd7f6485",
  "step_number": 5,
  "model_id": "30cc08ec-465c-4041-898e-a08e3889cee9"
}
```

---

### Step 6: Cloud Credential (If Cloud Model)

```json
{
  "name": "test-111",
  "tags": [],
  "description": "test-111",
  "concurrent_requests": 50,
  "eval_with": "configuration",
  "workflow_id": "9e4aa5c6-d2df-42ab-8972-a954bd7f6485",
  "step_number": 6,
  "credential_id": "22d4bb50-d574-4cb1-8b09-0b00138b2bcc"
}
```

---

### Step 7: User Confirmation

```json
{
  "name": "test-111",
  "tags": [],
  "description": "test-111",
  "concurrent_requests": 50,
  "eval_with": "configuration",
  "workflow_id": "9e4aa5c6-d2df-42ab-8972-a954bd7f6485",
  "step_number": 7,
  "user_confirmation": true
}
```

---

### Step 8: Execute

```json
{
  "name": "test-111",
  "tags": [],
  "description": "test-111",
  "concurrent_requests": 50,
  "eval_with": "configuration",
  "workflow_id": "9e4aa5c6-d2df-42ab-8972-a954bd7f6485",
  "step_number": 8,
  "run_as_simulation": false,
  "trigger_workflow": true
}
```

Step 8 leads to below sub-steps which are performed by budcluster microservice.
- Verify cluster connection
- Transfer model to cluster (this step is skipped if benchmark is requested for cloud model)
- Deploy model engine
  - for cloud model, deployed engine is instance of litellm server.
  - for local model, deployed engine is instance of budruntime server.
- Verify model deployment
- Run performance benchmark

If any of the steps fail, error event is published to budapp microservice from budcluster microservice.
Cleanup is performed in both success and failure conditions. Deployed model is deleted and cluster resources are freed.

# List all benchmarks

API: GET /benchmark

```python
curl -X 'GET' \
  'https://bud-app-dev.bud.studio/benchmark?page=1&limit=1&search=true&name=test-11' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer <token>'
```

Sample Response:

```json
{
  "object": "benchmarks.list",
  "message": "Successfully list all benchmarks",
  "page": 1,
  "limit": 1,
  "total_record": 3,
  "benchmarks": [
    {
      "id": "220f5283-121b-480e-91e8-b71097f2877f",
      "name": "test-111",
      "status": "processing",
      "model": {
        "id": "30cc08ec-465c-4041-898e-a08e3889cee9",
        "name": "chatgpt-3-5",
        "author": null,
        "modality": "llm",
        "source": "openai",
        "uri": "gpt-3.5-turbo-0125",
        "created_user": null,
        "model_size": null,
        "tasks": [],
        "tags": [
          {
            "name": "cloud",
            "color": "#479D5F"
          },
          {
            "name": "openai",
            "color": "#D1B854"
          },
          {
            "name": "gpt-3.5-turbo",
            "color": "#EEEEEE"
          }
        ],
        "icon": null,
        "description": "Fine-tuning for GPT-3.5 Turbo is now available, with fine-tuning for GPT-4 coming this fall. This update gives developers the ability to customize models that perform better for their use cases and run these custom models at scale. Early tests have shown a fine-tuned version of GPT-3.5 Turbo can match, or even outperform, base GPT-4-level capabilities on certain narrow ta",
        "provider_type": "cloud_model",
        "created_at": "2025-01-03T22:19:14.213380Z",
        "modified_at": "2025-04-15T13:26:27.089755Z",
        "provider": null,
        "is_present_in_model": null,
        "model_cluster_recommended": null
      },
      "cluster": {
        "id": "1fbb9c3c-4198-4e7e-8a1e-02b86041ea82",
        "name": "Dev cluster",
        "icon": "üòç",
        "ingress_url": "http://20.244.107.114:13025/",
        "cluster_type": "ON_PERM",
        "created_at": "2025-03-05T14:23:09.647681Z",
        "modified_at": "2025-03-24T00:33:25.049724Z",
        "status": "available",
        "cluster_id": "ef8b285a-07ef-4659-bb90-d5a96f57789f",
        "cpu_count": 1,
        "gpu_count": 0,
        "hpu_count": 0,
        "cpu_total_workers": 1,
        "cpu_available_workers": 1,
        "gpu_total_workers": 0,
        "gpu_available_workers": 0,
        "hpu_total_workers": 0,
        "hpu_available_workers": 0,
        "total_nodes": 1,
        "available_nodes": 1
      },
      "node_type": "cpu",
      "vendor_type": "AMD EPYC 7763 64-Core Processor",
      "concurrency": 50,
      "tpot": 0.44,
      "ttft": 0.2,
      "created_at": "2025-03-20T19:12:15.633452Z",
      "eval_with": "configuration",
      "dataset_ids": null,
      "max_input_tokens": 50,
      "max_output_tokens": 100
    }
  ],
  "total_pages": 3
}
```

# Get benchmark result

API: GET /benchmark/result

```python
curl -X 'GET' \
  'https://bud-app-dev.bud.studio/benchmark/result?benchmark_id=58f55925-ff56-4db6-93d1-df39bae9d3b5' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer <token>'
```

Sample Response :

```json
{
  "object": "benchmark.result",
  "message": "Successfully fetched benchmark result",
  "param": {
    "result": {
      "p75_throughput": 4.300698902318045,
      "p25_ttft_ms": 2569.148689508438,
      "p25_tpot_ms": 0.015527673531323673,
      "p25_itl_ms": 0.004825007636100054,
      "p25_e2el_ms": 2569.315565750003,
      "modified_at": "2025-04-02T08:33:53.117246Z",
      "successful_requests": 10,
      "p95_throughput": 4.588590623106642,
      "p75_ttft_ms": 3401.8989767646417,
      "p75_tpot_ms": 0.021012703655287623,
      "p75_itl_ms": 0.009750074241310358,
      "p75_e2el_ms": 3402.0501280319877,
      "total_input_tokens": 362,
      "p99_throughput": 4.624298499975314,
      "p95_ttft_ms": 5160.884857946074,
      "p95_tpot_ms": 0.02514269552193582,
      "p95_itl_ms": 2447.7159860543898,
      "p95_e2el_ms": 5161.0546293319185,
      "duration": 5.881510099163279,
      "total_output_tokens": 110,
      "min_throughput": 1.8702679778727054,
      "p99_ttft_ms": 5737.269610133953,
      "p99_tpot_ms": 0.026204691035673026,
      "p99_itl_ms": 3850.991507018908,
      "p99_e2el_ms": 5737.419005197007,
      "benchmark_id": "b05ee56a-72a3-4b25-b66a-87f9b33cead0",
      "id": "621bc745-d815-447b-9a1f-ee03aed51bf9",
      "request_throughput": 38.91524578973733,
      "max_throughput": 4.633225469192483,
      "min_ttft_ms": 2373.891287948936,
      "min_tpot_ms": 0.014430098235607147,
      "min_itl_ms": 0.0036009587347507477,
      "min_e2el_ms": 2374.1559898480773,
      "input_throughput": 1408.7318975884914,
      "mean_ttft_ms": 3348.7767771352082,
      "max_ttft_ms": 5881.365798180923,
      "max_tpot_ms": 0.026470189914107323,
      "max_itl_ms": 5881.365798180923,
      "max_e2el_ms": 5881.510099163279,
      "output_throughput": 7.13446172811851,
      "median_ttft_ms": 3190.8154611010104,
      "mean_tpot_ms": 0.0189321581274271,
      "mean_itl_ms": 223.25901988117644,
      "mean_e2el_ms": 3348.9660987164825,
      "created_at": "2025-04-02T08:33:53.117240Z",
      "p25_throughput": 3.233348778128036,
      "median_tpot_ms": 0.01861514756456018,
      "median_itl_ms": 0.0073499977588653564,
      "median_e2el_ms": 3191.0227625630796
    }
  }
}
```

# Fetch model and cluster details of a benchmark

API: GET /benchmark/<benchmark_id>/model-cluster-detail

```python
curl -X 'GET' \
  'https://bud-app-dev.bud.studio/benchmark/58f55925-ff56-4db6-93d1-df39bae9d3b5/model-cluster-detail' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer <token>'
```
Sample Response :

```json
{
  "object": "benchmark.model.cluster.detail",
  "message": "Successfully fetched model cluster detail for the benchmark.",
  "result": {
    "id": "58f55925-ff56-4db6-93d1-df39bae9d3b5",
    "name": "sonali-321",
    "status": "success",
    "model": {
      "id": "30cc08ec-465c-4041-898e-a08e3889cee9",
      "name": "chatgpt-3-5",
      "description": "Fine-tuning for GPT-3.5 Turbo is now available, with fine-tuning for GPT-4 coming this fall. This update gives developers the ability to customize models that perform better for their use cases and run these custom models at scale. Early tests have shown a fine-tuned version of GPT-3.5 Turbo can match, or even outperform, base GPT-4-level capabilities on certain narrow ta",
      "tags": [
        {
          "name": "cloud",
          "color": "#479D5F"
        },
        {
          "name": "openai",
          "color": "#D1B854"
        },
        {
          "name": "gpt-3.5-turbo",
          "color": "#EEEEEE"
        }
      ],
      "tasks": [],
      "author": null,
      "model_size": null,
      "icon": null,
      "github_url": "https://github.com/BudEcosystem/",
      "huggingface_url": "https://github.com/BudEcosystem/",
      "website_url": "https://www.google.com/",
      "bud_verified": false,
      "scan_verified": false,
      "eval_verified": false,
      "strengths": null,
      "limitations": null,
      "languages": null,
      "use_cases": null,
      "minimum_requirements": null,
      "examples": null,
      "base_model": null,
      "model_type": null,
      "family": null,
      "model_weights_size": null,
      "kv_cache_size": null,
      "architecture_text_config": null,
      "architecture_vision_config": null,
      "modality": "llm",
      "source": "openai",
      "provider_type": "cloud_model",
      "uri": "gpt-3.5-turbo-0125",
      "paper_published": [
        {
          "id": "d3fe40c2-9252-4f24-9174-7279cfcf6b36",
          "title": "Untitled Research Paper",
          "authors": null,
          "url": "https://n/",
          "model_id": "30cc08ec-465c-4041-898e-a08e3889cee9"
        },
        {
          "id": "f88b67ae-ac95-497b-95b8-bda68ab43c93",
          "title": "Untitled Research Paper",
          "authors": null,
          "url": "https://saurabhharak.medium.com/fine-tuning-davinci-002-a-practical-guide-for-enhanced-llm-performance-f2b3ca2e8661",
          "model_id": "30cc08ec-465c-4041-898e-a08e3889cee9"
        },
        {
          "id": "108bb085-2dd2-4bfe-8277-db10042c3f74",
          "title": "Untitled Research Paper",
          "authors": null,
          "url": "https://worldofwork.io/2019/08/the-grow-coaching-model",
          "model_id": "30cc08ec-465c-4041-898e-a08e3889cee9"
        }
      ],
      "model_licenses": {
        "id": "61365faa-8a66-445d-a1f9-124005590e89",
        "name": "Template_RS21.docx.pdf",
        "url": null,
        "path": "licenses/Template_RS21.docx.pdf",
        "faqs": null,
        "license_type": null,
        "description": null,
        "suitability": null,
        "model_id": "30cc08ec-465c-4041-898e-a08e3889cee9",
        "data_type": "url"
      },
      "provider": {
        "id": "1c64b7bf-7302-45f1-bd3d-2405a23a9111",
        "name": "OpenAI",
        "description": "Offers advanced models for language, image generation, and audio conversion.",
        "type": "openai",
        "icon": "icons/providers/openai.png"
      },
      "created_at": "2025-01-03T22:19:14.213380Z"
    },
    "cluster": {
      "id": "2c3ec72b-d8b6-41a6-8425-7e046c6f3966",
      "name": "SPR Cluster",
      "icon": "üöÑ",
      "ingress_url": "http://20.244.107.114:10701/",
      "cluster_type": "ON_PREM",
      "created_at": "2025-03-29T16:53:33.995735Z",
      "modified_at": "2025-04-07T13:33:35.078512Z",
      "status": "available",
      "cluster_id": "60d5a04c-cebc-4d2d-a106-9f4fcc5cabe7",
      "cpu_count": 2,
      "gpu_count": 0,
      "hpu_count": 0,
      "cpu_total_workers": 16,
      "cpu_available_workers": 16,
      "gpu_total_workers": 0,
      "gpu_available_workers": 0,
      "hpu_total_workers": 0,
      "hpu_available_workers": 0,
      "total_nodes": 2,
      "available_nodes": 2
    },
    "deployment_config": null
  }
}
```

# Fetch relationship data of any two outputs of a benchmark

API: POST /benchmark/<benchmark_id>/analysis/field1_vs_field2

Acceptable values for field1 and field2:
- ttft
- tpot
- latency
- prompt_len
- output_len
- req_output_throughput
- itl

```python
curl -X 'POST' \
  'https://bud-app-dev.bud.studio/benchmark/58f55925-ff56-4db6-93d1-df39bae9d3b5/analysis/field1_vs_field2?field1=prompt_len&field2=tpot' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer <token>'
```
Sample Response :

```json
{
  "object": "benchmark.request.metrics.detail",
  "message": "Successfully fetched prompt_len vs tpot analysis data for benchmark : 58f55925-ff56-4db6-93d1-df39bae9d3b5.",
  "param": {
    "result": [
      {
        "prompt_len": 64,
        "tpot": 0.00001582009717822075
      },
      {
        "prompt_len": 12,
        "tpot": 0.000019290205091238023
      },
      {
        "prompt_len": 12,
        "tpot": 0.000020090187899768352
      },
      {
        "prompt_len": 8,
        "tpot": 0.000015430198982357978
      },
      {
        "prompt_len": 26,
        "tpot": 0.00002352020237594843
      },
      {
        "prompt_len": 9,
        "tpot": 0.000026470189914107324
      },
      {
        "prompt_len": 16,
        "tpot": 0.000021320208907127382
      },
      {
        "prompt_len": 30,
        "tpot": 0.000014430098235607148
      },
      {
        "prompt_len": 157,
        "tpot": 0.00001794009003788233
      },
      {
        "prompt_len": 28,
        "tpot": 0.000015010102652013302
      }
    ]
  }
}
```

# Add benchmark request metrics to benchmark_request_metrics table in budapp's db

API: POST /benchmark/request-metrics

This API is used internally. Not exposed to the user.

# Fetch benchmark's request metrics data for benchmark detail page table

API: GET /benchmark/request-metrics

```python
curl -X 'GET' \
  'https://bud-app-dev.bud.studio/benchmark/request-metrics?benchmark_id=58f55925-ff56-4db6-93d1-df39bae9d3b5&page=1&limit=1' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer <token>'
```
Sample Response :

```json
{
  "object": "benchmark.request.metrics.list",
  "page": 1,
  "limit": 1,
  "total_items": 10,
  "total_pages": 10,
  "items": [
    {
      "benchmark_id": "58f55925-ff56-4db6-93d1-df39bae9d3b5",
      "dataset_id": "3557d4d7-d8dc-4bd3-8969-8d5d572bb45e",
      "latency": 2.465739300008863,
      "success": true,
      "error": "",
      "prompt_len": 64,
      "output_len": 11,
      "req_output_throughput": 4.461136665972944,
      "ttft": 2.465581099037081,
      "tpot": 0.00001582009717822075,
      "itl": [
        2.465581099037081,
        0.000009500188753008842,
        0.000006200047209858894,
        0.00000509992241859436,
        0.000013800105080008507,
        0.0000057998113334178925,
        0.000004899920895695686,
        0.000006600050255656242,
        0.000004699919372797012,
        0.000004200031980872154,
        0.00000400003045797348,
        0.00000409991480410099,
        0.000003899913281202316,
        0.0000038000289350748062,
        0.0000037010759115219116
      ],
      "itl_sum": 2.465661399997771
    }
  ]
}
```

# Fetch input-distribution of a benchmark with evaluation method dataset 

API: POST /benchmark/dataset/input-distribution

```python
curl -X 'POST' \
  'https://bud-app-dev.bud.studio/benchmark/dataset/input-distribution?benchmark_id=58f55925-ff56-4db6-93d1-df39bae9d3b5&num_bins=2' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer <token>' \
  -H 'Content-Type: application/json' \
  -d '["d830e2ab-756a-4819-a7e5-6fe1e6751275"]'
```
Sample Response :

```json
{
  "object": "benchmark.dataset.input.distribution",
  "message": "Successfully fetched dataset input distribution",
  "param": {
    "result": [
      {
        "bin_id": 1,
        "bin_range": "0.0-78.5",
        "avg_ttft": 3.71,
        "avg_tpot": 0,
        "avg_latency": 3.71,
        "p95_ttft": 5.51,
        "p95_tpot": 0,
        "p95_latency": 5.51,
        "avg_output_len": 11
      },
      {
        "bin_id": 2,
        "bin_range": "78.5-157.1",
        "avg_ttft": 3.27,
        "avg_tpot": 0,
        "avg_latency": 3.27,
        "p95_ttft": 3.27,
        "p95_tpot": 0,
        "p95_latency": 3.27,
        "avg_output_len": 11
      }
    ]
  }
}
```

# Fetch output-distribution of a benchmark with evaluation method dataset 

API: POST /benchmark/dataset/output-distribution

```python
curl -X 'POST' \
  'https://bud-app-dev.bud.studio/benchmark/dataset/output-distribution?benchmark_id=58f55925-ff56-4db6-93d1-df39bae9d3b5&num_bins=2' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer <token>' \
  -H 'Content-Type: application/json' \
  -d '["d830e2ab-756a-4819-a7e5-6fe1e6751275"]'
```
Sample Response :

```json
{
  "object": "benchmark.dataset.input.distribution",
  "message": "Successfully fetched dataset output distribution",
  "param": {
    "result": [
      {
        "bin_id": 1,
        "bin_range": "0.0-5.5",
        "avg_ttft": 0,
        "avg_tpot": 0,
        "avg_latency": 0,
        "p95_ttft": 0,
        "p95_tpot": 0,
        "p95_latency": 0
      },
      {
        "bin_id": 2,
        "bin_range": "5.5-11.1",
        "avg_ttft": 3.62,
        "avg_tpot": 0,
        "avg_latency": 3.62,
        "p95_ttft": 5.39,
        "p95_tpot": 0,
        "p95_latency": 5.39
      }
    ]
  }
}
```