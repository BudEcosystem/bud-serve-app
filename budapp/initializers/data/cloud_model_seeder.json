{
    "openai": {
        "models": [
            {
                "name": "gpt-4",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "gpt-4o",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4o",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-05
                }
            },
            {
                "name": "gpt-4o-audio-preview",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4o-audio-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-05
                }
            },
            {
                "name": "gpt-4o-audio-preview-2024-10-01",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4o-audio-preview-2024-10-01",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-05
                }
            },
            {
                "name": "gpt-4o-mini",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4o-mini",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "gpt-4o-mini-2024-07-18",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4o-mini-2024-07-18",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "o1-mini",
                "modality": "llm",
                "source": "openai",
                "uri": "o1-mini",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 4.4e-06
                }
            },
            {
                "name": "o1-mini-2024-09-12",
                "modality": "llm",
                "source": "openai",
                "uri": "o1-mini-2024-09-12",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.2e-05
                }
            },
            {
                "name": "o1-preview",
                "modality": "llm",
                "source": "openai",
                "uri": "o1-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "o1-preview-2024-09-12",
                "modality": "llm",
                "source": "openai",
                "uri": "o1-preview-2024-09-12",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "chatgpt-4o-latest",
                "modality": "llm",
                "source": "openai",
                "uri": "chatgpt-4o-latest",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "gpt-4o-2024-05-13",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4o-2024-05-13",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "gpt-4o-2024-08-06",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4o-2024-08-06",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-05
                }
            },
            {
                "name": "gpt-4-turbo-preview",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-turbo-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "gpt-4-0314",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-0314",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "gpt-4-0613",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-0613",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "gpt-4-32k",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-32k",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 6e-05
                },
                "output_cost": {
                    "output_cost_per_token": 0.00012
                }
            },
            {
                "name": "gpt-4-32k-0314",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-32k-0314",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 6e-05
                },
                "output_cost": {
                    "output_cost_per_token": 0.00012
                }
            },
            {
                "name": "gpt-4-32k-0613",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-32k-0613",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 6e-05
                },
                "output_cost": {
                    "output_cost_per_token": 0.00012
                }
            },
            {
                "name": "gpt-4-turbo",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-turbo",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "gpt-4-turbo-2024-04-09",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-turbo-2024-04-09",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "gpt-4-1106-preview",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-1106-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "gpt-4-0125-preview",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-0125-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "gpt-4-vision-preview",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-vision-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "gpt-4-1106-vision-preview",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-4-1106-vision-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "gpt-3.5-turbo",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-3.5-turbo",
                "max_input_tokens": 16385,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "gpt-3.5-turbo-0301",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-3.5-turbo-0301",
                "max_input_tokens": 4097,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "gpt-3.5-turbo-0613",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-3.5-turbo-0613",
                "max_input_tokens": 4097,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "gpt-3.5-turbo-1106",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-3.5-turbo-1106",
                "max_input_tokens": 16385,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "gpt-3.5-turbo-0125",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-3.5-turbo-0125",
                "max_input_tokens": 16385,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "gpt-3.5-turbo-16k",
                "modality": "llm",
                "source": "openai",
                "uri": "gpt-3.5-turbo-16k",
                "max_input_tokens": 16385,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 4e-06
                }
            },
            {
                "name": "ft:gpt-3.5-turbo",
                "modality": "llm",
                "source": "openai",
                "uri": "ft:gpt-3.5-turbo",
                "max_input_tokens": 16385,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 6e-06
                }
            },
            {
                "name": "ft:gpt-3.5-turbo-0125",
                "modality": "llm",
                "source": "openai",
                "uri": "ft:gpt-3.5-turbo-0125",
                "max_input_tokens": 16385,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 6e-06
                }
            },
            {
                "name": "ft:gpt-3.5-turbo-1106",
                "modality": "llm",
                "source": "openai",
                "uri": "ft:gpt-3.5-turbo-1106",
                "max_input_tokens": 16385,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 6e-06
                }
            },
            {
                "name": "ft:gpt-3.5-turbo-0613",
                "modality": "llm",
                "source": "openai",
                "uri": "ft:gpt-3.5-turbo-0613",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 6e-06
                }
            },
            {
                "name": "ft:gpt-4-0613",
                "modality": "llm",
                "source": "openai",
                "uri": "ft:gpt-4-0613",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "ft:gpt-4o-2024-08-06",
                "modality": "llm",
                "source": "openai",
                "uri": "ft:gpt-4o-2024-08-06",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3.75e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "ft:gpt-4o-mini-2024-07-18",
                "modality": "llm",
                "source": "openai",
                "uri": "ft:gpt-4o-mini-2024-07-18",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.2e-06
                }
            },
            {
                "name": "text-embedding-3-large",
                "modality": "embedding",
                "source": "openai",
                "uri": "text-embedding-3-large",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 1.3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "text-embedding-3-small",
                "modality": "embedding",
                "source": "openai",
                "uri": "text-embedding-3-small",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 2e-08
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "text-embedding-ada-002",
                "modality": "embedding",
                "source": "openai",
                "uri": "text-embedding-ada-002",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "text-embedding-ada-002-v2",
                "modality": "embedding",
                "source": "openai",
                "uri": "text-embedding-ada-002-v2",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "256-x-256/dall-e-2",
                "modality": "image",
                "source": "openai",
                "uri": "256-x-256/dall-e-2",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "512-x-512/dall-e-2",
                "modality": "image",
                "source": "openai",
                "uri": "512-x-512/dall-e-2",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "1024-x-1024/dall-e-2",
                "modality": "image",
                "source": "openai",
                "uri": "1024-x-1024/dall-e-2",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "hd/1024-x-1792/dall-e-3",
                "modality": "image",
                "source": "openai",
                "uri": "hd/1024-x-1792/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "hd/1792-x-1024/dall-e-3",
                "modality": "image",
                "source": "openai",
                "uri": "hd/1792-x-1024/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "hd/1024-x-1024/dall-e-3",
                "modality": "image",
                "source": "openai",
                "uri": "hd/1024-x-1024/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "standard/1024-x-1792/dall-e-3",
                "modality": "image",
                "source": "openai",
                "uri": "standard/1024-x-1792/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "standard/1792-x-1024/dall-e-3",
                "modality": "image",
                "source": "openai",
                "uri": "standard/1792-x-1024/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "standard/1024-x-1024/dall-e-3",
                "modality": "image",
                "source": "openai",
                "uri": "standard/1024-x-1024/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "whisper-1",
                "modality": "speech_to_text",
                "source": "openai",
                "uri": "whisper-1",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "tts-1",
                "modality": "text_to_speech",
                "source": "openai",
                "uri": "tts-1",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "tts-1-hd",
                "modality": "text_to_speech",
                "source": "openai",
                "uri": "tts-1-hd",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            }
        ]
    },
    "text-completion-openai": {
        "models": [
            {
                "name": "ft:davinci-002",
                "modality": "llm",
                "source": "text-completion-openai",
                "uri": "ft:davinci-002",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "ft:babbage-002",
                "modality": "llm",
                "source": "text-completion-openai",
                "uri": "ft:babbage-002",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 4e-07
                },
                "output_cost": {
                    "output_cost_per_token": 4e-07
                }
            },
            {
                "name": "azure/gpt-3.5-turbo-instruct-0914",
                "modality": "llm",
                "source": "text-completion-openai",
                "uri": "azure/gpt-3.5-turbo-instruct-0914",
                "max_input_tokens": 4097,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "azure/gpt-35-turbo-instruct",
                "modality": "llm",
                "source": "text-completion-openai",
                "uri": "azure/gpt-35-turbo-instruct",
                "max_input_tokens": 4097,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "azure/gpt-35-turbo-instruct-0914",
                "modality": "llm",
                "source": "text-completion-openai",
                "uri": "azure/gpt-35-turbo-instruct-0914",
                "max_input_tokens": 4097,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "babbage-002",
                "modality": "llm",
                "source": "text-completion-openai",
                "uri": "babbage-002",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 4e-07
                },
                "output_cost": {
                    "output_cost_per_token": 4e-07
                }
            },
            {
                "name": "davinci-002",
                "modality": "llm",
                "source": "text-completion-openai",
                "uri": "davinci-002",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "gpt-3.5-turbo-instruct",
                "modality": "llm",
                "source": "text-completion-openai",
                "uri": "gpt-3.5-turbo-instruct",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "gpt-3.5-turbo-instruct-0914",
                "modality": "llm",
                "source": "text-completion-openai",
                "uri": "gpt-3.5-turbo-instruct-0914",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            }
        ]
    },
    "azure": {
        "models": [
            {
                "name": "azure/tts-1",
                "modality": "text_to_speech",
                "source": "azure",
                "uri": "azure/tts-1",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "azure/tts-1-hd",
                "modality": "text_to_speech",
                "source": "azure",
                "uri": "azure/tts-1-hd",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "azure/whisper-1",
                "modality": "speech_to_text",
                "source": "azure",
                "uri": "azure/whisper-1",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "azure/o1-mini",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/o1-mini",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.21e-06
                },
                "output_cost": {
                    "output_cost_per_token": 4.84e-06
                }
            },
            {
                "name": "azure/o1-mini-2024-09-12",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/o1-mini-2024-09-12",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.21e-06
                },
                "output_cost": {
                    "output_cost_per_token": 4.84e-06
                }
            },
            {
                "name": "azure/o1-preview",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/o1-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "azure/o1-preview-2024-09-12",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/o1-preview-2024-09-12",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "azure/gpt-4o",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4o",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "azure/gpt-4o-2024-08-06",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4o-2024-08-06",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2.75e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.1e-05
                }
            },
            {
                "name": "azure/gpt-4o-2024-05-13",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4o-2024-05-13",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "azure/global-standard/gpt-4o-2024-08-06",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/global-standard/gpt-4o-2024-08-06",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-05
                }
            },
            {
                "name": "azure/global-standard/gpt-4o-mini",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/global-standard/gpt-4o-mini",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "azure/gpt-4o-mini",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4o-mini",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.65e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6.6e-07
                }
            },
            {
                "name": "azure/gpt-4-turbo-2024-04-09",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4-turbo-2024-04-09",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "azure/gpt-4-0125-preview",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4-0125-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "azure/gpt-4-1106-preview",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4-1106-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "azure/gpt-4-0613",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4-0613",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "azure/gpt-4-32k-0613",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4-32k-0613",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 6e-05
                },
                "output_cost": {
                    "output_cost_per_token": 0.00012
                }
            },
            {
                "name": "azure/gpt-4-32k",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4-32k",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 6e-05
                },
                "output_cost": {
                    "output_cost_per_token": 0.00012
                }
            },
            {
                "name": "azure/gpt-4",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "azure/gpt-4-turbo",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4-turbo",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "azure/gpt-4-turbo-vision-preview",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-4-turbo-vision-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "azure/gpt-35-turbo-16k-0613",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-35-turbo-16k-0613",
                "max_input_tokens": 16385,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 4e-06
                }
            },
            {
                "name": "azure/gpt-35-turbo-1106",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-35-turbo-1106",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "azure/gpt-35-turbo-0613",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-35-turbo-0613",
                "max_input_tokens": 4097,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "azure/gpt-35-turbo-0301",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-35-turbo-0301",
                "max_input_tokens": 4097,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "azure/gpt-35-turbo-0125",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-35-turbo-0125",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "azure/gpt-35-turbo-16k",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-35-turbo-16k",
                "max_input_tokens": 16385,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 4e-06
                }
            },
            {
                "name": "azure/gpt-35-turbo",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/gpt-35-turbo",
                "max_input_tokens": 4097,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "azure/mistral-large-latest",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/mistral-large-latest",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "azure/mistral-large-2402",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/mistral-large-2402",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "azure/command-r-plus",
                "modality": "llm",
                "source": "azure",
                "uri": "azure/command-r-plus",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "azure/ada",
                "modality": "embedding",
                "source": "azure",
                "uri": "azure/ada",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "azure/text-embedding-ada-002",
                "modality": "embedding",
                "source": "azure",
                "uri": "azure/text-embedding-ada-002",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "azure/text-embedding-3-large",
                "modality": "embedding",
                "source": "azure",
                "uri": "azure/text-embedding-3-large",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 1.3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "azure/text-embedding-3-small",
                "modality": "embedding",
                "source": "azure",
                "uri": "azure/text-embedding-3-small",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 2e-08
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "azure/standard/1024-x-1024/dall-e-3",
                "modality": "image",
                "source": "azure",
                "uri": "azure/standard/1024-x-1024/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "azure/hd/1024-x-1024/dall-e-3",
                "modality": "image",
                "source": "azure",
                "uri": "azure/hd/1024-x-1024/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "azure/standard/1024-x-1792/dall-e-3",
                "modality": "image",
                "source": "azure",
                "uri": "azure/standard/1024-x-1792/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "azure/standard/1792-x-1024/dall-e-3",
                "modality": "image",
                "source": "azure",
                "uri": "azure/standard/1792-x-1024/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "azure/hd/1024-x-1792/dall-e-3",
                "modality": "image",
                "source": "azure",
                "uri": "azure/hd/1024-x-1792/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "azure/hd/1792-x-1024/dall-e-3",
                "modality": "image",
                "source": "azure",
                "uri": "azure/hd/1792-x-1024/dall-e-3",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "azure/standard/1024-x-1024/dall-e-2",
                "modality": "image",
                "source": "azure",
                "uri": "azure/standard/1024-x-1024/dall-e-2",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            }
        ]
    },
    "azure_ai": {
        "models": [
            {
                "name": "azure_ai/jamba-instruct",
                "modality": "llm",
                "source": "azure_ai",
                "uri": "azure_ai/jamba-instruct",
                "max_input_tokens": 70000,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7e-07
                }
            },
            {
                "name": "azure_ai/mistral-large",
                "modality": "llm",
                "source": "azure_ai",
                "uri": "azure_ai/mistral-large",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 4e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.2e-05
                }
            },
            {
                "name": "azure_ai/mistral-small",
                "modality": "llm",
                "source": "azure_ai",
                "uri": "azure_ai/mistral-small",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3e-06
                }
            },
            {
                "name": "azure_ai/Meta-Llama-3-70B-Instruct",
                "modality": "llm",
                "source": "azure_ai",
                "uri": "azure_ai/Meta-Llama-3-70B-Instruct",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3.7e-07
                }
            },
            {
                "name": "azure_ai/Meta-Llama-3.1-8B-Instruct",
                "modality": "llm",
                "source": "azure_ai",
                "uri": "azure_ai/Meta-Llama-3.1-8B-Instruct",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6.1e-07
                }
            },
            {
                "name": "azure_ai/Meta-Llama-3.1-70B-Instruct",
                "modality": "llm",
                "source": "azure_ai",
                "uri": "azure_ai/Meta-Llama-3.1-70B-Instruct",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2.68e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3.54e-06
                }
            },
            {
                "name": "azure_ai/Meta-Llama-3.1-405B-Instruct",
                "modality": "llm",
                "source": "azure_ai",
                "uri": "azure_ai/Meta-Llama-3.1-405B-Instruct",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 5.33e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.6e-05
                }
            },
            {
                "name": "azure_ai/Cohere-embed-v3-english",
                "modality": "embedding",
                "source": "azure_ai",
                "uri": "azure_ai/Cohere-embed-v3-english",
                "max_input_tokens": 512,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "azure_ai/Cohere-embed-v3-multilingual",
                "modality": "embedding",
                "source": "azure_ai",
                "uri": "azure_ai/Cohere-embed-v3-multilingual",
                "max_input_tokens": 512,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            }
        ]
    },
    "mistral": {
        "models": [
            {
                "name": "mistral/mistral-tiny",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/mistral-tiny",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.5e-07
                }
            },
            {
                "name": "mistral/mistral-small",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/mistral-small",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "mistral/mistral-small-latest",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/mistral-small-latest",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "mistral/mistral-medium",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/mistral-medium",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 2.7e-06
                },
                "output_cost": {
                    "output_cost_per_token": 8.1e-06
                }
            },
            {
                "name": "mistral/mistral-medium-latest",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/mistral-medium-latest",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 2.7e-06
                },
                "output_cost": {
                    "output_cost_per_token": 8.1e-06
                }
            },
            {
                "name": "mistral/mistral-medium-2312",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/mistral-medium-2312",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 2.7e-06
                },
                "output_cost": {
                    "output_cost_per_token": 8.1e-06
                }
            },
            {
                "name": "mistral/mistral-large-latest",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/mistral-large-latest",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 6e-06
                }
            },
            {
                "name": "mistral/mistral-large-2402",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/mistral-large-2402",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 4e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.2e-05
                }
            },
            {
                "name": "mistral/mistral-large-2407",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/mistral-large-2407",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 9e-06
                }
            },
            {
                "name": "mistral/pixtral-12b-2409",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/pixtral-12b-2409",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-07
                }
            },
            {
                "name": "mistral/open-mistral-7b",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/open-mistral-7b",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.5e-07
                }
            },
            {
                "name": "mistral/open-mixtral-8x7b",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/open-mixtral-8x7b",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7e-07
                }
            },
            {
                "name": "mistral/open-mixtral-8x22b",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/open-mixtral-8x22b",
                "max_input_tokens": 65336,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 6e-06
                }
            },
            {
                "name": "mistral/codestral-latest",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/codestral-latest",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3e-06
                }
            },
            {
                "name": "mistral/codestral-2405",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/codestral-2405",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3e-06
                }
            },
            {
                "name": "mistral/open-mistral-nemo",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/open-mistral-nemo",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "mistral/open-mistral-nemo-2407",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/open-mistral-nemo-2407",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "mistral/open-codestral-mamba",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/open-codestral-mamba",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.5e-07
                }
            },
            {
                "name": "mistral/codestral-mamba-latest",
                "modality": "llm",
                "source": "mistral",
                "uri": "mistral/codestral-mamba-latest",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.5e-07
                }
            },
            {
                "name": "mistral/mistral-embed",
                "modality": "embedding",
                "source": "mistral",
                "uri": "mistral/mistral-embed",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            }
        ]
    },
    "deepseek": {
        "models": [
            {
                "name": "deepseek-chat",
                "modality": "llm",
                "source": "deepseek",
                "uri": "deepseek-chat"
            },
            {
                "name": "deepseek-coder",
                "modality": "llm",
                "source": "deepseek",
                "uri": "deepseek-coder"
            }
        ]
    },
    "codestral": {
        "models": [
            {
                "name": "codestral/codestral-latest",
                "modality": "llm",
                "source": "codestral",
                "uri": "codestral/codestral-latest",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "codestral/codestral-2405",
                "modality": "llm",
                "source": "codestral",
                "uri": "codestral/codestral-2405",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            }
        ]
    },
    "text-completion-codestral": {
        "models": [
            {
                "name": "text-completion-codestral/codestral-latest",
                "modality": "llm",
                "source": "text-completion-codestral",
                "uri": "text-completion-codestral/codestral-latest",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "text-completion-codestral/codestral-2405",
                "modality": "llm",
                "source": "text-completion-codestral",
                "uri": "text-completion-codestral/codestral-2405",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            }
        ]
    },
    "groq": {
        "models": [
            {
                "name": "groq/llama2-70b-4096",
                "modality": "llm",
                "source": "groq",
                "uri": "groq/llama2-70b-4096",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 8e-07
                }
            },
            {
                "name": "groq/llama3-8b-8192",
                "modality": "llm",
                "source": "groq",
                "uri": "groq/llama3-8b-8192",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 8e-08
                }
            },
            {
                "name": "groq/llama3-70b-8192",
                "modality": "llm",
                "source": "groq",
                "uri": "groq/llama3-70b-8192",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 5.9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7.9e-07
                }
            },
            {
                "name": "groq/llama-3.1-8b-instant",
                "modality": "llm",
                "source": "groq",
                "uri": "groq/llama-3.1-8b-instant",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 8e-08
                }
            },
            {
                "name": "groq/llama-3.1-70b-versatile",
                "modality": "llm",
                "source": "groq",
                "uri": "groq/llama-3.1-70b-versatile",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 5.9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7.9e-07
                }
            },
            {
                "name": "groq/llama-3.1-405b-reasoning",
                "modality": "llm",
                "source": "groq",
                "uri": "groq/llama-3.1-405b-reasoning",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 5.9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7.9e-07
                }
            },
            {
                "name": "groq/mixtral-8x7b-32768",
                "modality": "llm",
                "source": "groq",
                "uri": "groq/mixtral-8x7b-32768",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 2.4e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-07
                }
            },
            {
                "name": "groq/gemma-7b-it",
                "modality": "llm",
                "source": "groq",
                "uri": "groq/gemma-7b-it",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 7e-08
                },
                "output_cost": {
                    "output_cost_per_token": 7e-08
                }
            },
            {
                "name": "groq/gemma2-9b-it",
                "modality": "llm",
                "source": "groq",
                "uri": "groq/gemma2-9b-it",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "groq/llama3-groq-70b-8192-tool-use-preview",
                "modality": "llm",
                "source": "groq",
                "uri": "groq/llama3-groq-70b-8192-tool-use-preview",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 8.9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 8.9e-07
                }
            },
            {
                "name": "groq/llama3-groq-8b-8192-tool-use-preview",
                "modality": "llm",
                "source": "groq",
                "uri": "groq/llama3-groq-8b-8192-tool-use-preview",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.9e-07
                }
            }
        ]
    },
    "cerebras": {
        "models": [
            {
                "name": "cerebras/llama3.1-8b",
                "modality": "llm",
                "source": "cerebras",
                "uri": "cerebras/llama3.1-8b",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1e-07
                }
            },
            {
                "name": "cerebras/llama3.1-70b",
                "modality": "llm",
                "source": "cerebras",
                "uri": "cerebras/llama3.1-70b",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 6e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            }
        ]
    },
    "friendliai": {
        "models": [
            {
                "name": "friendliai/mixtral-8x7b-instruct-v0-1",
                "modality": "llm",
                "source": "friendliai",
                "uri": "friendliai/mixtral-8x7b-instruct-v0-1"
            },
            {
                "name": "friendliai/meta-llama-3-8b-instruct",
                "modality": "llm",
                "source": "friendliai",
                "uri": "friendliai/meta-llama-3-8b-instruct"
            },
            {
                "name": "friendliai/meta-llama-3-70b-instruct",
                "modality": "llm",
                "source": "friendliai",
                "uri": "friendliai/meta-llama-3-70b-instruct"
            }
        ]
    },
    "vertex_ai-text-models": {
        "models": [
            {
                "name": "text-bison",
                "modality": "llm",
                "source": "vertex_ai-text-models",
                "uri": "text-bison",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_character": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_character": 5e-07
                }
            },
            {
                "name": "text-bison@001",
                "modality": "llm",
                "source": "vertex_ai-text-models",
                "uri": "text-bison@001",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_character": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_character": 5e-07
                }
            },
            {
                "name": "text-bison@002",
                "modality": "llm",
                "source": "vertex_ai-text-models",
                "uri": "text-bison@002",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_character": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_character": 5e-07
                }
            },
            {
                "name": "text-bison32k",
                "modality": "llm",
                "source": "vertex_ai-text-models",
                "uri": "text-bison32k",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "text-bison32k@002",
                "modality": "llm",
                "source": "vertex_ai-text-models",
                "uri": "text-bison32k@002",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "text-unicorn",
                "modality": "llm",
                "source": "vertex_ai-text-models",
                "uri": "text-unicorn",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-05
                }
            },
            {
                "name": "text-unicorn@001",
                "modality": "llm",
                "source": "vertex_ai-text-models",
                "uri": "text-unicorn@001",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-05
                }
            }
        ]
    },
    "vertex_ai-chat-models": {
        "models": [
            {
                "name": "chat-bison",
                "modality": "llm",
                "source": "vertex_ai-chat-models",
                "uri": "chat-bison",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "chat-bison@001",
                "modality": "llm",
                "source": "vertex_ai-chat-models",
                "uri": "chat-bison@001",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "chat-bison@002",
                "modality": "llm",
                "source": "vertex_ai-chat-models",
                "uri": "chat-bison@002",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "chat-bison-32k",
                "modality": "llm",
                "source": "vertex_ai-chat-models",
                "uri": "chat-bison-32k",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "chat-bison-32k@002",
                "modality": "llm",
                "source": "vertex_ai-chat-models",
                "uri": "chat-bison-32k@002",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            }
        ]
    },
    "vertex_ai-code-text-models": {
        "models": [
            {
                "name": "code-bison",
                "modality": "llm",
                "source": "vertex_ai-code-text-models",
                "uri": "code-bison",
                "max_input_tokens": 6144,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "code-bison@001",
                "modality": "llm",
                "source": "vertex_ai-code-text-models",
                "uri": "code-bison@001",
                "max_input_tokens": 6144,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "code-bison@002",
                "modality": "llm",
                "source": "vertex_ai-code-text-models",
                "uri": "code-bison@002",
                "max_input_tokens": 6144,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "code-bison32k",
                "modality": "llm",
                "source": "vertex_ai-code-text-models",
                "uri": "code-bison32k",
                "max_input_tokens": 6144,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "code-bison-32k@002",
                "modality": "llm",
                "source": "vertex_ai-code-text-models",
                "uri": "code-bison-32k@002",
                "max_input_tokens": 6144,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "code-gecko@001",
                "modality": "llm",
                "source": "vertex_ai-code-text-models",
                "uri": "code-gecko@001",
                "max_input_tokens": 2048,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "code-gecko@002",
                "modality": "llm",
                "source": "vertex_ai-code-text-models",
                "uri": "code-gecko@002",
                "max_input_tokens": 2048,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "code-gecko",
                "modality": "llm",
                "source": "vertex_ai-code-text-models",
                "uri": "code-gecko",
                "max_input_tokens": 2048,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "code-gecko-latest",
                "modality": "llm",
                "source": "vertex_ai-code-text-models",
                "uri": "code-gecko-latest",
                "max_input_tokens": 2048,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            }
        ]
    },
    "vertex_ai-code-chat-models": {
        "models": [
            {
                "name": "codechat-bison@latest",
                "modality": "llm",
                "source": "vertex_ai-code-chat-models",
                "uri": "codechat-bison@latest",
                "max_input_tokens": 6144,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "codechat-bison",
                "modality": "llm",
                "source": "vertex_ai-code-chat-models",
                "uri": "codechat-bison",
                "max_input_tokens": 6144,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "codechat-bison@001",
                "modality": "llm",
                "source": "vertex_ai-code-chat-models",
                "uri": "codechat-bison@001",
                "max_input_tokens": 6144,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "codechat-bison@002",
                "modality": "llm",
                "source": "vertex_ai-code-chat-models",
                "uri": "codechat-bison@002",
                "max_input_tokens": 6144,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "codechat-bison-32k",
                "modality": "llm",
                "source": "vertex_ai-code-chat-models",
                "uri": "codechat-bison-32k",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            },
            {
                "name": "codechat-bison-32k@002",
                "modality": "llm",
                "source": "vertex_ai-code-chat-models",
                "uri": "codechat-bison-32k@002",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-07
                }
            }
        ]
    },
    "vertex_ai-language-models": {
        "models": [
            {
                "name": "gemini-pro",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-pro",
                "max_input_tokens": 32760,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "gemini-1.0-pro",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.0-pro",
                "max_input_tokens": 32760,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "gemini-1.0-pro-001",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.0-pro-001",
                "max_input_tokens": 32760,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "gemini-1.0-ultra",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.0-ultra",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "gemini-1.0-ultra-001",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.0-ultra-001",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "gemini-1.0-pro-002",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.0-pro-002",
                "max_input_tokens": 32760,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "gemini-1.5-pro",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.5-pro",
                "max_input_tokens": 2097152,
                "input_cost": {
                    "input_cost_per_token": 1.25e-06
                },
                "output_cost": {
                    "output_cost_per_token": 5e-06
                }
            },
            {
                "name": "gemini-1.5-pro-002",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.5-pro-002",
                "max_input_tokens": 2097152,
                "input_cost": {
                    "input_cost_per_token": 1.25e-06
                },
                "output_cost": {
                    "output_cost_per_token": 5e-06
                }
            },
            {
                "name": "gemini-1.5-pro-001",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.5-pro-001",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 1.25e-06
                },
                "output_cost": {
                    "output_cost_per_token": 5e-06
                }
            },
            {
                "name": "gemini-1.5-pro-preview-0514",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.5-pro-preview-0514",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 7.8125e-08
                },
                "output_cost": {
                    "output_cost_per_token": 3.125e-07
                }
            },
            {
                "name": "gemini-1.5-pro-preview-0215",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.5-pro-preview-0215",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 7.8125e-08
                },
                "output_cost": {
                    "output_cost_per_token": 3.125e-07
                }
            },
            {
                "name": "gemini-1.5-pro-preview-0409",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.5-pro-preview-0409",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 7.8125e-08
                },
                "output_cost": {
                    "output_cost_per_token": 3.125e-07
                }
            },
            {
                "name": "gemini-1.5-flash",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.5-flash",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 7.5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "gemini-1.5-flash-exp-0827",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.5-flash-exp-0827",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 4.688e-09
                },
                "output_cost": {
                    "output_cost_per_token": 4.6875e-09
                }
            },
            {
                "name": "gemini-1.5-flash-002",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.5-flash-002",
                "max_input_tokens": 1048576,
                "input_cost": {
                    "input_cost_per_token": 7.5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "gemini-1.5-flash-001",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.5-flash-001",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 7.5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "gemini-1.5-flash-preview-0514",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-1.5-flash-preview-0514",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 7.5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 4.6875e-09
                }
            },
            {
                "name": "gemini-pro-experimental",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-pro-experimental",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 0
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "gemini-flash-experimental",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "gemini-flash-experimental",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 0
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "medlm-medium",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "medlm-medium",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_character": 5e-07
                },
                "output_cost": {
                    "output_cost_per_character": 1e-06
                }
            },
            {
                "name": "medlm-large",
                "modality": "llm",
                "source": "vertex_ai-language-models",
                "uri": "medlm-large",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_character": 5e-06
                },
                "output_cost": {
                    "output_cost_per_character": 1.5e-05
                }
            }
        ]
    },
    "vertex_ai-vision-models": {
        "models": [
            {
                "name": "gemini-pro-vision",
                "modality": "llm",
                "source": "vertex_ai-vision-models",
                "uri": "gemini-pro-vision",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "gemini-1.0-pro-vision",
                "modality": "llm",
                "source": "vertex_ai-vision-models",
                "uri": "gemini-1.0-pro-vision",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "gemini-1.0-pro-vision-001",
                "modality": "llm",
                "source": "vertex_ai-vision-models",
                "uri": "gemini-1.0-pro-vision-001",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            }
        ]
    },
    "vertex_ai-anthropic_models": {
        "models": [
            {
                "name": "vertex_ai/claude-3-sonnet@20240229",
                "modality": "llm",
                "source": "vertex_ai-anthropic_models",
                "uri": "vertex_ai/claude-3-sonnet@20240229",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "vertex_ai/claude-3-5-sonnet@20240620",
                "modality": "llm",
                "source": "vertex_ai-anthropic_models",
                "uri": "vertex_ai/claude-3-5-sonnet@20240620",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "vertex_ai/claude-3-5-sonnet-v2@20241022",
                "modality": "llm",
                "source": "vertex_ai-anthropic_models",
                "uri": "vertex_ai/claude-3-5-sonnet-v2@20241022",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "vertex_ai/claude-3-haiku@20240307",
                "modality": "llm",
                "source": "vertex_ai-anthropic_models",
                "uri": "vertex_ai/claude-3-haiku@20240307",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-06
                }
            },
            {
                "name": "vertex_ai/claude-3-opus@20240229",
                "modality": "llm",
                "source": "vertex_ai-anthropic_models",
                "uri": "vertex_ai/claude-3-opus@20240229",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 7.5e-05
                }
            }
        ]
    },
    "vertex_ai-llama_models": {
        "models": [
            {
                "name": "vertex_ai/meta/llama3-405b-instruct-maas",
                "modality": "llm",
                "source": "vertex_ai-llama_models",
                "uri": "vertex_ai/meta/llama3-405b-instruct-maas",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "vertex_ai/meta/llama3-70b-instruct-maas",
                "modality": "llm",
                "source": "vertex_ai-llama_models",
                "uri": "vertex_ai/meta/llama3-70b-instruct-maas",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "vertex_ai/meta/llama3-8b-instruct-maas",
                "modality": "llm",
                "source": "vertex_ai-llama_models",
                "uri": "vertex_ai/meta/llama3-8b-instruct-maas",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas",
                "modality": "llm",
                "source": "vertex_ai-llama_models",
                "uri": "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            }
        ]
    },
    "vertex_ai-mistral_models": {
        "models": [
            {
                "name": "vertex_ai/mistral-large@latest",
                "modality": "llm",
                "source": "vertex_ai-mistral_models",
                "uri": "vertex_ai/mistral-large@latest",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 6e-06
                }
            },
            {
                "name": "vertex_ai/mistral-large@2407",
                "modality": "llm",
                "source": "vertex_ai-mistral_models",
                "uri": "vertex_ai/mistral-large@2407",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 6e-06
                }
            },
            {
                "name": "vertex_ai/mistral-nemo@latest",
                "modality": "llm",
                "source": "vertex_ai-mistral_models",
                "uri": "vertex_ai/mistral-nemo@latest",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-07
                }
            },
            {
                "name": "vertex_ai/mistral-nemo@2407",
                "modality": "llm",
                "source": "vertex_ai-mistral_models",
                "uri": "vertex_ai/mistral-nemo@2407",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3e-06
                }
            },
            {
                "name": "vertex_ai/codestral@latest",
                "modality": "llm",
                "source": "vertex_ai-mistral_models",
                "uri": "vertex_ai/codestral@latest",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "vertex_ai/codestral@2405",
                "modality": "llm",
                "source": "vertex_ai-mistral_models",
                "uri": "vertex_ai/codestral@2405",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            }
        ]
    },
    "vertex_ai-ai21_models": {
        "models": [
            {
                "name": "vertex_ai/jamba-1.5-mini@001",
                "modality": "llm",
                "source": "vertex_ai-ai21_models",
                "uri": "vertex_ai/jamba-1.5-mini@001",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 4e-07
                }
            },
            {
                "name": "vertex_ai/jamba-1.5-large@001",
                "modality": "llm",
                "source": "vertex_ai-ai21_models",
                "uri": "vertex_ai/jamba-1.5-large@001",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 8e-06
                }
            },
            {
                "name": "vertex_ai/jamba-1.5",
                "modality": "llm",
                "source": "vertex_ai-ai21_models",
                "uri": "vertex_ai/jamba-1.5",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 4e-07
                }
            },
            {
                "name": "vertex_ai/jamba-1.5-mini",
                "modality": "llm",
                "source": "vertex_ai-ai21_models",
                "uri": "vertex_ai/jamba-1.5-mini",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 4e-07
                }
            },
            {
                "name": "vertex_ai/jamba-1.5-large",
                "modality": "llm",
                "source": "vertex_ai-ai21_models",
                "uri": "vertex_ai/jamba-1.5-large",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 8e-06
                }
            }
        ]
    },
    "vertex_ai-image-models": {
        "models": [
            {
                "name": "vertex_ai/imagegeneration@006",
                "modality": "image",
                "source": "vertex_ai-image-models",
                "uri": "vertex_ai/imagegeneration@006",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "vertex_ai/imagen-3.0-generate-001",
                "modality": "image",
                "source": "vertex_ai-image-models",
                "uri": "vertex_ai/imagen-3.0-generate-001",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "vertex_ai/imagen-3.0-fast-generate-001",
                "modality": "image",
                "source": "vertex_ai-image-models",
                "uri": "vertex_ai/imagen-3.0-fast-generate-001",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            }
        ]
    },
    "vertex_ai-embedding-models": {
        "models": [
            {
                "name": "text-embedding-004",
                "modality": "embedding",
                "source": "vertex_ai-embedding-models",
                "uri": "text-embedding-004",
                "max_input_tokens": 2048,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "text-multilingual-embedding-002",
                "modality": "embedding",
                "source": "vertex_ai-embedding-models",
                "uri": "text-multilingual-embedding-002",
                "max_input_tokens": 2048,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "textembedding-gecko",
                "modality": "embedding",
                "source": "vertex_ai-embedding-models",
                "uri": "textembedding-gecko",
                "max_input_tokens": 3072,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "textembedding-gecko-multilingual",
                "modality": "embedding",
                "source": "vertex_ai-embedding-models",
                "uri": "textembedding-gecko-multilingual",
                "max_input_tokens": 3072,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "textembedding-gecko-multilingual@001",
                "modality": "embedding",
                "source": "vertex_ai-embedding-models",
                "uri": "textembedding-gecko-multilingual@001",
                "max_input_tokens": 3072,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "textembedding-gecko@001",
                "modality": "embedding",
                "source": "vertex_ai-embedding-models",
                "uri": "textembedding-gecko@001",
                "max_input_tokens": 3072,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "textembedding-gecko@003",
                "modality": "embedding",
                "source": "vertex_ai-embedding-models",
                "uri": "textembedding-gecko@003",
                "max_input_tokens": 3072,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "text-embedding-preview-0409",
                "modality": "embedding",
                "source": "vertex_ai-embedding-models",
                "uri": "text-embedding-preview-0409",
                "max_input_tokens": 3072,
                "input_cost": {
                    "input_cost_per_token": 6.25e-09
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "text-multilingual-embedding-preview-0409",
                "modality": "embedding",
                "source": "vertex_ai-embedding-models",
                "uri": "text-multilingual-embedding-preview-0409",
                "max_input_tokens": 3072,
                "input_cost": {
                    "input_cost_per_token": 6.25e-09
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            }
        ]
    },
    "gemini": {
        "models": [
            {
                "name": "gemini/gemini-1.5-flash-002",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-flash-002",
                "max_input_tokens": 1048576,
                "input_cost": {
                    "input_cost_per_token": 7.5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "gemini/gemini-1.5-flash-001",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-flash-001",
                "max_input_tokens": 1048576,
                "input_cost": {
                    "input_cost_per_token": 7.5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "gemini/gemini-1.5-flash",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-flash",
                "max_input_tokens": 1048576,
                "input_cost": {
                    "input_cost_per_token": 7.5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "gemini/gemini-1.5-flash-latest",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-flash-latest",
                "max_input_tokens": 1048576,
                "input_cost": {
                    "input_cost_per_token": 7.5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "gemini/gemini-1.5-flash-8b-exp-0924",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-flash-8b-exp-0924",
                "max_input_tokens": 1048576,
                "input_cost": {
                    "input_cost_per_token": 0
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "gemini/gemini-1.5-flash-exp-0827",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-flash-exp-0827",
                "max_input_tokens": 1048576,
                "input_cost": {
                    "input_cost_per_token": 0
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "gemini/gemini-1.5-flash-8b-exp-0827",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-flash-8b-exp-0827",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 0
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "gemini/gemini-pro",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-pro",
                "max_input_tokens": 32760,
                "input_cost": {
                    "input_cost_per_token": 3.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.05e-06
                }
            },
            {
                "name": "gemini/gemini-1.5-pro",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-pro",
                "max_input_tokens": 2097152,
                "input_cost": {
                    "input_cost_per_token": 3.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.05e-05
                }
            },
            {
                "name": "gemini/gemini-1.5-pro-002",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-pro-002",
                "max_input_tokens": 2097152,
                "input_cost": {
                    "input_cost_per_token": 3.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.05e-05
                }
            },
            {
                "name": "gemini/gemini-1.5-pro-001",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-pro-001",
                "max_input_tokens": 2097152,
                "input_cost": {
                    "input_cost_per_token": 3.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.05e-05
                }
            },
            {
                "name": "gemini/gemini-1.5-pro-exp-0801",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-pro-exp-0801",
                "max_input_tokens": 2097152,
                "input_cost": {
                    "input_cost_per_token": 3.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.05e-05
                }
            },
            {
                "name": "gemini/gemini-1.5-pro-exp-0827",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-pro-exp-0827",
                "max_input_tokens": 2097152,
                "input_cost": {
                    "input_cost_per_token": 0
                },
                "output_cost": {
                    "output_cost_per_token": 0
                }
            },
            {
                "name": "gemini/gemini-1.5-pro-latest",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-1.5-pro-latest",
                "max_input_tokens": 1048576,
                "input_cost": {
                    "input_cost_per_token": 3.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.05e-06
                }
            },
            {
                "name": "gemini/gemini-pro-vision",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-pro-vision",
                "max_input_tokens": 30720,
                "input_cost": {
                    "input_cost_per_token": 3.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.05e-06
                }
            },
            {
                "name": "gemini/gemini-gemma-2-27b-it",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-gemma-2-27b-it",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 3.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.05e-06
                }
            },
            {
                "name": "gemini/gemini-gemma-2-9b-it",
                "modality": "llm",
                "source": "gemini",
                "uri": "gemini/gemini-gemma-2-9b-it",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 3.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.05e-06
                }
            }
        ]
    },
    "cohere_chat": {
        "models": [
            {
                "name": "command-r",
                "modality": "llm",
                "source": "cohere_chat",
                "uri": "command-r",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "command-r-08-2024",
                "modality": "llm",
                "source": "cohere_chat",
                "uri": "command-r-08-2024",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "command-light",
                "modality": "llm",
                "source": "cohere_chat",
                "uri": "command-light",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "command-r-plus",
                "modality": "llm",
                "source": "cohere_chat",
                "uri": "command-r-plus",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-05
                }
            },
            {
                "name": "command-r-plus-08-2024",
                "modality": "llm",
                "source": "cohere_chat",
                "uri": "command-r-plus-08-2024",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-05
                }
            }
        ]
    },
    "cohere": {
        "models": [
            {
                "name": "command-nightly",
                "modality": "llm",
                "source": "cohere",
                "uri": "command-nightly",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "command",
                "modality": "llm",
                "source": "cohere",
                "uri": "command",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "embed-english-light-v3.0",
                "modality": "embedding",
                "source": "cohere",
                "uri": "embed-english-light-v3.0",
                "max_input_tokens": 1024,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "embed-multilingual-v3.0",
                "modality": "embedding",
                "source": "cohere",
                "uri": "embed-multilingual-v3.0",
                "max_input_tokens": 1024,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "embed-english-v2.0",
                "modality": "embedding",
                "source": "cohere",
                "uri": "embed-english-v2.0",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "embed-english-light-v2.0",
                "modality": "embedding",
                "source": "cohere",
                "uri": "embed-english-light-v2.0",
                "max_input_tokens": 1024,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "embed-multilingual-v2.0",
                "modality": "embedding",
                "source": "cohere",
                "uri": "embed-multilingual-v2.0",
                "max_input_tokens": 768,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "embed-english-v3.0",
                "modality": "embedding",
                "source": "cohere",
                "uri": "embed-english-v3.0",
                "max_input_tokens": 1024,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            }
        ]
    },
    "replicate": {
        "models": [
            {
                "name": "replicate/meta/llama-2-13b",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/meta/llama-2-13b",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 5e-07
                }
            },
            {
                "name": "replicate/meta/llama-2-13b-chat",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/meta/llama-2-13b-chat",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 5e-07
                }
            },
            {
                "name": "replicate/meta/llama-2-70b",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/meta/llama-2-70b",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 6.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.75e-06
                }
            },
            {
                "name": "replicate/meta/llama-2-70b-chat",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/meta/llama-2-70b-chat",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 6.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.75e-06
                }
            },
            {
                "name": "replicate/meta/llama-2-7b",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/meta/llama-2-7b",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 2.5e-07
                }
            },
            {
                "name": "replicate/meta/llama-2-7b-chat",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/meta/llama-2-7b-chat",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 2.5e-07
                }
            },
            {
                "name": "replicate/meta/llama-3-70b",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/meta/llama-3-70b",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 6.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.75e-06
                }
            },
            {
                "name": "replicate/meta/llama-3-70b-instruct",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/meta/llama-3-70b-instruct",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 6.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.75e-06
                }
            },
            {
                "name": "replicate/meta/llama-3-8b",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/meta/llama-3-8b",
                "max_input_tokens": 8086,
                "input_cost": {
                    "input_cost_per_token": 5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 2.5e-07
                }
            },
            {
                "name": "replicate/meta/llama-3-8b-instruct",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/meta/llama-3-8b-instruct",
                "max_input_tokens": 8086,
                "input_cost": {
                    "input_cost_per_token": 5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 2.5e-07
                }
            },
            {
                "name": "replicate/mistralai/mistral-7b-v0.1",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/mistralai/mistral-7b-v0.1",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 2.5e-07
                }
            },
            {
                "name": "replicate/mistralai/mistral-7b-instruct-v0.2",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/mistralai/mistral-7b-instruct-v0.2",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 5e-08
                },
                "output_cost": {
                    "output_cost_per_token": 2.5e-07
                }
            },
            {
                "name": "replicate/mistralai/mixtral-8x7b-instruct-v0.1",
                "modality": "llm",
                "source": "replicate",
                "uri": "replicate/mistralai/mixtral-8x7b-instruct-v0.1",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1e-06
                }
            }
        ]
    },
    "openrouter": {
        "models": [
            {
                "name": "openrouter/deepseek/deepseek-coder",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/deepseek/deepseek-coder",
                "max_input_tokens": 66000,
                "input_cost": {
                    "input_cost_per_token": 1.4e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-07
                }
            },
            {
                "name": "openrouter/microsoft/wizardlm-2-8x22b:nitro",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/microsoft/wizardlm-2-8x22b:nitro",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-06
                }
            },
            {
                "name": "openrouter/google/gemini-pro-1.5",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/google/gemini-pro-1.5",
                "max_input_tokens": 1000000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 7.5e-06
                }
            },
            {
                "name": "openrouter/mistralai/mixtral-8x22b-instruct",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/mistralai/mixtral-8x22b-instruct",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 6.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6.5e-07
                }
            },
            {
                "name": "openrouter/cohere/command-r-plus",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/cohere/command-r-plus",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "openrouter/databricks/dbrx-instruct",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/databricks/dbrx-instruct",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 6e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "openrouter/anthropic/claude-3-haiku",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/anthropic/claude-3-haiku",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-06
                }
            },
            {
                "name": "openrouter/anthropic/claude-3-haiku-20240307",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/anthropic/claude-3-haiku-20240307",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-06
                }
            },
            {
                "name": "openrouter/anthropic/claude-3.5-sonnet",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/anthropic/claude-3.5-sonnet",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "openrouter/anthropic/claude-3.5-sonnet:beta",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/anthropic/claude-3.5-sonnet:beta",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "openrouter/anthropic/claude-3-sonnet",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/anthropic/claude-3-sonnet",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "openrouter/mistralai/mistral-large",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/mistralai/mistral-large",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "openrouter/cognitivecomputations/dolphin-mixtral-8x7b",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/cognitivecomputations/dolphin-mixtral-8x7b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 5e-07
                }
            },
            {
                "name": "openrouter/google/gemini-pro-vision",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/google/gemini-pro-vision",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 3.75e-07
                }
            },
            {
                "name": "openrouter/fireworks/firellava-13b",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/fireworks/firellava-13b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "openrouter/meta-llama/llama-3-8b-instruct:free",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/meta-llama/llama-3-8b-instruct:free",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "openrouter/meta-llama/llama-3-8b-instruct:extended",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/meta-llama/llama-3-8b-instruct:extended",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 2.25e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.25e-06
                }
            },
            {
                "name": "openrouter/meta-llama/llama-3-70b-instruct:nitro",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/meta-llama/llama-3-70b-instruct:nitro",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9e-07
                }
            },
            {
                "name": "openrouter/meta-llama/llama-3-70b-instruct",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/meta-llama/llama-3-70b-instruct",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 5.9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7.9e-07
                }
            },
            {
                "name": "openrouter/openai/o1-mini",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/openai/o1-mini",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.2e-05
                }
            },
            {
                "name": "openrouter/openai/o1-mini-2024-09-12",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/openai/o1-mini-2024-09-12",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.2e-05
                }
            },
            {
                "name": "openrouter/openai/o1-preview",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/openai/o1-preview",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "openrouter/openai/o1-preview-2024-09-12",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/openai/o1-preview-2024-09-12",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "openrouter/openai/gpt-4o",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/openai/gpt-4o",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "openrouter/openai/gpt-4o-2024-05-13",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/openai/gpt-4o-2024-05-13",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "openrouter/openai/gpt-4-vision-preview",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/openai/gpt-4-vision-preview",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3e-05
                }
            },
            {
                "name": "openrouter/openai/gpt-3.5-turbo",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/openai/gpt-3.5-turbo",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "openrouter/openai/gpt-3.5-turbo-16k",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/openai/gpt-3.5-turbo-16k",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 4e-06
                }
            },
            {
                "name": "openrouter/openai/gpt-4",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/openai/gpt-4",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 3e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6e-05
                }
            },
            {
                "name": "openrouter/anthropic/claude-instant-v1",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/anthropic/claude-instant-v1",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.63e-06
                },
                "output_cost": {
                    "output_cost_per_token": 5.51e-06
                }
            },
            {
                "name": "openrouter/anthropic/claude-2",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/anthropic/claude-2",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.102e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3.268e-05
                }
            },
            {
                "name": "openrouter/anthropic/claude-3-opus",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/anthropic/claude-3-opus",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 7.5e-05
                }
            },
            {
                "name": "openrouter/google/palm-2-chat-bison",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/google/palm-2-chat-bison",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 5e-07
                }
            },
            {
                "name": "openrouter/google/palm-2-codechat-bison",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/google/palm-2-codechat-bison",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 5e-07
                }
            },
            {
                "name": "openrouter/meta-llama/llama-2-13b-chat",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/meta-llama/llama-2-13b-chat",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "openrouter/meta-llama/llama-2-70b-chat",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/meta-llama/llama-2-70b-chat",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "openrouter/meta-llama/codellama-34b-instruct",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/meta-llama/codellama-34b-instruct",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 5e-07
                }
            },
            {
                "name": "openrouter/nousresearch/nous-hermes-llama2-13b",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/nousresearch/nous-hermes-llama2-13b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "openrouter/mancer/weaver",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/mancer/weaver",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 5.625e-06
                },
                "output_cost": {
                    "output_cost_per_token": 5.625e-06
                }
            },
            {
                "name": "openrouter/gryphe/mythomax-l2-13b",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/gryphe/mythomax-l2-13b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.875e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.875e-06
                }
            },
            {
                "name": "openrouter/jondurbin/airoboros-l2-70b-2.1",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/jondurbin/airoboros-l2-70b-2.1",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.3875e-05
                },
                "output_cost": {
                    "output_cost_per_token": 1.3875e-05
                }
            },
            {
                "name": "openrouter/undi95/remm-slerp-l2-13b",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/undi95/remm-slerp-l2-13b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.875e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.875e-06
                }
            },
            {
                "name": "openrouter/pygmalionai/mythalion-13b",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/pygmalionai/mythalion-13b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.875e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.875e-06
                }
            },
            {
                "name": "openrouter/mistralai/mistral-7b-instruct",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/mistralai/mistral-7b-instruct",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.3e-07
                }
            },
            {
                "name": "openrouter/mistralai/mistral-7b-instruct:free",
                "modality": "llm",
                "source": "openrouter",
                "uri": "openrouter/mistralai/mistral-7b-instruct:free",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            }
        ]
    },
    "ai21": {
        "models": [
            {
                "name": "j2-ultra",
                "modality": "llm",
                "source": "ai21",
                "uri": "j2-ultra",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "jamba-1.5-mini@001",
                "modality": "llm",
                "source": "ai21",
                "uri": "jamba-1.5-mini@001",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 4e-07
                }
            },
            {
                "name": "jamba-1.5-large@001",
                "modality": "llm",
                "source": "ai21",
                "uri": "jamba-1.5-large@001",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 8e-06
                }
            },
            {
                "name": "jamba-1.5",
                "modality": "llm",
                "source": "ai21",
                "uri": "jamba-1.5",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 4e-07
                }
            },
            {
                "name": "jamba-1.5-mini",
                "modality": "llm",
                "source": "ai21",
                "uri": "jamba-1.5-mini",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 4e-07
                }
            },
            {
                "name": "jamba-1.5-large",
                "modality": "llm",
                "source": "ai21",
                "uri": "jamba-1.5-large",
                "max_input_tokens": 256000,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 8e-06
                }
            },
            {
                "name": "j2-mid",
                "modality": "llm",
                "source": "ai21",
                "uri": "j2-mid",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1e-05
                },
                "output_cost": {
                    "output_cost_per_token": 1e-05
                }
            },
            {
                "name": "j2-light",
                "modality": "llm",
                "source": "ai21",
                "uri": "j2-light",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3e-06
                }
            }
        ]
    },
    "nlp_cloud": {
        "models": [
            {
                "name": "dolphin",
                "modality": "llm",
                "source": "nlp_cloud",
                "uri": "dolphin",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 5e-07
                }
            },
            {
                "name": "chatdolphin",
                "modality": "llm",
                "source": "nlp_cloud",
                "uri": "chatdolphin",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 5e-07
                }
            }
        ]
    },
    "aleph_alpha": {
        "models": [
            {
                "name": "luminous-base",
                "modality": "llm",
                "source": "aleph_alpha",
                "uri": "luminous-base",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 3e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3.3e-05
                }
            },
            {
                "name": "luminous-base-control",
                "modality": "llm",
                "source": "aleph_alpha",
                "uri": "luminous-base-control",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 3.75e-05
                },
                "output_cost": {
                    "output_cost_per_token": 4.125e-05
                }
            },
            {
                "name": "luminous-extended",
                "modality": "llm",
                "source": "aleph_alpha",
                "uri": "luminous-extended",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 4.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 4.95e-05
                }
            },
            {
                "name": "luminous-extended-control",
                "modality": "llm",
                "source": "aleph_alpha",
                "uri": "luminous-extended-control",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 5.625e-05
                },
                "output_cost": {
                    "output_cost_per_token": 6.1875e-05
                }
            },
            {
                "name": "luminous-supreme",
                "modality": "llm",
                "source": "aleph_alpha",
                "uri": "luminous-supreme",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 0.000175
                },
                "output_cost": {
                    "output_cost_per_token": 0.0001925
                }
            },
            {
                "name": "luminous-supreme-control",
                "modality": "llm",
                "source": "aleph_alpha",
                "uri": "luminous-supreme-control",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 0.00021875
                },
                "output_cost": {
                    "output_cost_per_token": 0.000240625
                }
            }
        ]
    },
    "bedrock": {
        "models": [
            {
                "name": "ai21.j2-mid-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "ai21.j2-mid-v1",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 1.25e-05
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-05
                }
            },
            {
                "name": "ai21.j2-ultra-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "ai21.j2-ultra-v1",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 1.88e-05
                },
                "output_cost": {
                    "output_cost_per_token": 1.88e-05
                }
            },
            {
                "name": "ai21.jamba-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "ai21.jamba-instruct-v1:0",
                "max_input_tokens": 70000,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7e-07
                }
            },
            {
                "name": "amazon.titan-text-lite-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "amazon.titan-text-lite-v1",
                "max_input_tokens": 42000,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 4e-07
                }
            },
            {
                "name": "amazon.titan-text-express-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "amazon.titan-text-express-v1",
                "max_input_tokens": 42000,
                "input_cost": {
                    "input_cost_per_token": 1.3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.7e-06
                }
            },
            {
                "name": "amazon.titan-text-premier-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "amazon.titan-text-premier-v1:0",
                "max_input_tokens": 42000,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "amazon.titan-embed-text-v1",
                "modality": "embedding",
                "source": "bedrock",
                "uri": "amazon.titan-embed-text-v1",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "amazon.titan-embed-text-v2:0",
                "modality": "embedding",
                "source": "bedrock",
                "uri": "amazon.titan-embed-text-v2:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "mistral.mistral-7b-instruct-v0:2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "mistral.mistral-7b-instruct-v0:2",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "mistral.mixtral-8x7b-instruct-v0:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "mistral.mixtral-8x7b-instruct-v0:1",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 4.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7e-07
                }
            },
            {
                "name": "mistral.mistral-large-2402-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "mistral.mistral-large-2402-v1:0",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "mistral.mistral-large-2407-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "mistral.mistral-large-2407-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 9e-06
                }
            },
            {
                "name": "mistral.mistral-small-2402-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "mistral.mistral-small-2402-v1:0",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3e-06
                }
            },
            {
                "name": "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 4.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7e-07
                }
            },
            {
                "name": "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 4.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7e-07
                }
            },
            {
                "name": "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 5.9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9.1e-07
                }
            },
            {
                "name": "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.6e-07
                }
            },
            {
                "name": "bedrock/us-east-1/mistral.mistral-large-2402-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/mistral.mistral-large-2402-v1:0",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/us-west-2/mistral.mistral-large-2402-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/mistral.mistral-large-2402-v1:0",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1.04e-05
                },
                "output_cost": {
                    "output_cost_per_token": 3.12e-05
                }
            },
            {
                "name": "anthropic.claude-3-sonnet-20240229-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "anthropic.claude-3-sonnet-20240229-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "anthropic.claude-3-5-sonnet-20240620-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "anthropic.claude-3-5-sonnet-20240620-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "anthropic.claude-3-5-sonnet-20241022-v2:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "anthropic.claude-3-5-sonnet-20241022-v2:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "anthropic.claude-3-haiku-20240307-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "anthropic.claude-3-haiku-20240307-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-06
                }
            },
            {
                "name": "anthropic.claude-3-opus-20240229-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "anthropic.claude-3-opus-20240229-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 7.5e-05
                }
            },
            {
                "name": "us.anthropic.claude-3-sonnet-20240229-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "us.anthropic.claude-3-sonnet-20240229-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "us.anthropic.claude-3-haiku-20240307-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "us.anthropic.claude-3-haiku-20240307-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-06
                }
            },
            {
                "name": "us.anthropic.claude-3-opus-20240229-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "us.anthropic.claude-3-opus-20240229-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 7.5e-05
                }
            },
            {
                "name": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "eu.anthropic.claude-3-haiku-20240307-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "eu.anthropic.claude-3-haiku-20240307-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-06
                }
            },
            {
                "name": "eu.anthropic.claude-3-opus-20240229-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "eu.anthropic.claude-3-opus-20240229-v1:0",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 7.5e-05
                }
            },
            {
                "name": "anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/us-east-1/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/us-west-2/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/ap-northeast-1/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0455
                },
                "output_cost": {
                    "output_cost_per_second": 0.0455
                }
            },
            {
                "name": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.02527
                },
                "output_cost": {
                    "output_cost_per_second": 0.02527
                }
            },
            {
                "name": "bedrock/eu-central-1/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0415
                },
                "output_cost": {
                    "output_cost_per_second": 0.0415
                }
            },
            {
                "name": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.02305
                },
                "output_cost": {
                    "output_cost_per_second": 0.02305
                }
            },
            {
                "name": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0175
                },
                "output_cost": {
                    "output_cost_per_second": 0.0175
                }
            },
            {
                "name": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.00972
                },
                "output_cost": {
                    "output_cost_per_second": 0.00972
                }
            },
            {
                "name": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0175
                },
                "output_cost": {
                    "output_cost_per_second": 0.0175
                }
            },
            {
                "name": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.00972
                },
                "output_cost": {
                    "output_cost_per_second": 0.00972
                }
            },
            {
                "name": "anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/us-east-1/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/us-west-2/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/ap-northeast-1/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0455
                },
                "output_cost": {
                    "output_cost_per_second": 0.0455
                }
            },
            {
                "name": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.02527
                },
                "output_cost": {
                    "output_cost_per_second": 0.02527
                }
            },
            {
                "name": "bedrock/eu-central-1/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0415
                },
                "output_cost": {
                    "output_cost_per_second": 0.0415
                }
            },
            {
                "name": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.02305
                },
                "output_cost": {
                    "output_cost_per_second": 0.02305
                }
            },
            {
                "name": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0175
                },
                "output_cost": {
                    "output_cost_per_second": 0.0175
                }
            },
            {
                "name": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.00972
                },
                "output_cost": {
                    "output_cost_per_second": 0.00972
                }
            },
            {
                "name": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0175
                },
                "output_cost": {
                    "output_cost_per_second": 0.0175
                }
            },
            {
                "name": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.00972
                },
                "output_cost": {
                    "output_cost_per_second": 0.00972
                }
            },
            {
                "name": "anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/us-east-1/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/us-west-2/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/ap-northeast-1/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0455
                },
                "output_cost": {
                    "output_cost_per_second": 0.0455
                }
            },
            {
                "name": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.02527
                },
                "output_cost": {
                    "output_cost_per_second": 0.02527
                }
            },
            {
                "name": "bedrock/eu-central-1/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0415
                },
                "output_cost": {
                    "output_cost_per_second": 0.0415
                }
            },
            {
                "name": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.02305
                },
                "output_cost": {
                    "output_cost_per_second": 0.02305
                }
            },
            {
                "name": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0175
                },
                "output_cost": {
                    "output_cost_per_second": 0.0175
                }
            },
            {
                "name": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.00972
                },
                "output_cost": {
                    "output_cost_per_second": 0.00972
                }
            },
            {
                "name": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.0175
                },
                "output_cost": {
                    "output_cost_per_second": 0.0175
                }
            },
            {
                "name": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.00972
                },
                "output_cost": {
                    "output_cost_per_second": 0.00972
                }
            },
            {
                "name": "anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-06
                }
            },
            {
                "name": "bedrock/us-east-1/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-06
                }
            },
            {
                "name": "bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.011
                },
                "output_cost": {
                    "output_cost_per_second": 0.011
                }
            },
            {
                "name": "bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.00611
                },
                "output_cost": {
                    "output_cost_per_second": 0.00611
                }
            },
            {
                "name": "bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.011
                },
                "output_cost": {
                    "output_cost_per_second": 0.011
                }
            },
            {
                "name": "bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.00611
                },
                "output_cost": {
                    "output_cost_per_second": 0.00611
                }
            },
            {
                "name": "bedrock/us-west-2/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-2/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-06
                }
            },
            {
                "name": "bedrock/ap-northeast-1/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 2.23e-06
                },
                "output_cost": {
                    "output_cost_per_token": 7.55e-06
                }
            },
            {
                "name": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.01475
                },
                "output_cost": {
                    "output_cost_per_second": 0.01475
                }
            },
            {
                "name": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.008194
                },
                "output_cost": {
                    "output_cost_per_second": 0.008194
                }
            },
            {
                "name": "bedrock/eu-central-1/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 2.48e-06
                },
                "output_cost": {
                    "output_cost_per_token": 8.38e-06
                }
            },
            {
                "name": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.01635
                },
                "output_cost": {
                    "output_cost_per_second": 0.01635
                }
            },
            {
                "name": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_second": 0.009083
                },
                "output_cost": {
                    "output_cost_per_second": 0.009083
                }
            },
            {
                "name": "cohere.command-text-v14",
                "modality": "llm",
                "source": "bedrock",
                "uri": "cohere.command-text-v14",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1.5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "bedrock/*/1-month-commitment/cohere.command-text-v14",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/*/1-month-commitment/cohere.command-text-v14",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_second": 0.011
                },
                "output_cost": {
                    "output_cost_per_second": 0.011
                }
            },
            {
                "name": "bedrock/*/6-month-commitment/cohere.command-text-v14",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/*/6-month-commitment/cohere.command-text-v14",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_second": 0.0066027
                },
                "output_cost": {
                    "output_cost_per_second": 0.0066027
                }
            },
            {
                "name": "cohere.command-light-text-v14",
                "modality": "llm",
                "source": "bedrock",
                "uri": "cohere.command-light-text-v14",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "bedrock/*/1-month-commitment/cohere.command-light-text-v14",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/*/1-month-commitment/cohere.command-light-text-v14",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_second": 0.001902
                },
                "output_cost": {
                    "output_cost_per_second": 0.001902
                }
            },
            {
                "name": "bedrock/*/6-month-commitment/cohere.command-light-text-v14",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/*/6-month-commitment/cohere.command-light-text-v14",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_second": 0.0011416
                },
                "output_cost": {
                    "output_cost_per_second": 0.0011416
                }
            },
            {
                "name": "cohere.command-r-plus-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "cohere.command-r-plus-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "cohere.command-r-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "cohere.command-r-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "cohere.embed-english-v3",
                "modality": "embedding",
                "source": "bedrock",
                "uri": "cohere.embed-english-v3",
                "max_input_tokens": 512,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "cohere.embed-multilingual-v3",
                "modality": "embedding",
                "source": "bedrock",
                "uri": "cohere.embed-multilingual-v3",
                "max_input_tokens": 512,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "meta.llama2-13b-chat-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "meta.llama2-13b-chat-v1",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 7.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1e-06
                }
            },
            {
                "name": "meta.llama2-70b-chat-v1",
                "modality": "llm",
                "source": "bedrock",
                "uri": "meta.llama2-70b-chat-v1",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1.95e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.56e-06
                }
            },
            {
                "name": "meta.llama3-8b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "meta.llama3-8b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3.6e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7.2e-07
                }
            },
            {
                "name": "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6.9e-07
                }
            },
            {
                "name": "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3.2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6.5e-07
                }
            },
            {
                "name": "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3.9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7.8e-07
                }
            },
            {
                "name": "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.01e-06
                }
            },
            {
                "name": "meta.llama3-70b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "meta.llama3-70b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 2.65e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3.5e-06
                }
            },
            {
                "name": "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 2.65e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3.5e-06
                }
            },
            {
                "name": "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 2.65e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3.5e-06
                }
            },
            {
                "name": "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3.18e-06
                },
                "output_cost": {
                    "output_cost_per_token": 4.2e-06
                }
            },
            {
                "name": "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3.05e-06
                },
                "output_cost": {
                    "output_cost_per_token": 4.03e-06
                }
            },
            {
                "name": "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 2.86e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3.78e-06
                }
            },
            {
                "name": "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 3.45e-06
                },
                "output_cost": {
                    "output_cost_per_token": 4.55e-06
                }
            },
            {
                "name": "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 4.45e-06
                },
                "output_cost": {
                    "output_cost_per_token": 5.88e-06
                }
            },
            {
                "name": "meta.llama3-1-8b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "meta.llama3-1-8b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2.2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.2e-07
                }
            },
            {
                "name": "meta.llama3-1-70b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "meta.llama3-1-70b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 9.9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9.9e-07
                }
            },
            {
                "name": "meta.llama3-1-405b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "meta.llama3-1-405b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 5.32e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.6e-05
                }
            },
            {
                "name": "meta.llama3-2-1b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "meta.llama3-2-1b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1e-07
                }
            },
            {
                "name": "us.meta.llama3-2-1b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "us.meta.llama3-2-1b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1e-07
                }
            },
            {
                "name": "eu.meta.llama3-2-1b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "eu.meta.llama3-2-1b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.3e-07
                }
            },
            {
                "name": "meta.llama3-2-3b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "meta.llama3-2-3b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-07
                }
            },
            {
                "name": "us.meta.llama3-2-3b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "us.meta.llama3-2-3b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-07
                }
            },
            {
                "name": "eu.meta.llama3-2-3b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "eu.meta.llama3-2-3b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.9e-07
                }
            },
            {
                "name": "meta.llama3-2-11b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "meta.llama3-2-11b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 3.5e-07
                }
            },
            {
                "name": "us.meta.llama3-2-11b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "us.meta.llama3-2-11b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 3.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 3.5e-07
                }
            },
            {
                "name": "meta.llama3-2-90b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "meta.llama3-2-90b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "us.meta.llama3-2-90b-instruct-v1:0",
                "modality": "llm",
                "source": "bedrock",
                "uri": "us.meta.llama3-2-90b-instruct-v1:0",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2e-06
                }
            },
            {
                "name": "512-x-512/50-steps/stability.stable-diffusion-xl-v0",
                "modality": "image",
                "source": "bedrock",
                "uri": "512-x-512/50-steps/stability.stable-diffusion-xl-v0",
                "max_input_tokens": 77,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "512-x-512/max-steps/stability.stable-diffusion-xl-v0",
                "modality": "image",
                "source": "bedrock",
                "uri": "512-x-512/max-steps/stability.stable-diffusion-xl-v0",
                "max_input_tokens": 77,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "max-x-max/50-steps/stability.stable-diffusion-xl-v0",
                "modality": "image",
                "source": "bedrock",
                "uri": "max-x-max/50-steps/stability.stable-diffusion-xl-v0",
                "max_input_tokens": 77,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "max-x-max/max-steps/stability.stable-diffusion-xl-v0",
                "modality": "image",
                "source": "bedrock",
                "uri": "max-x-max/max-steps/stability.stable-diffusion-xl-v0",
                "max_input_tokens": 77,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1",
                "modality": "image",
                "source": "bedrock",
                "uri": "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1",
                "max_input_tokens": 77,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1",
                "modality": "image",
                "source": "bedrock",
                "uri": "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1",
                "max_input_tokens": 77,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            }
        ]
    },
    "sagemaker": {
        "models": [
            {
                "name": "sagemaker/meta-textgeneration-llama-2-7b",
                "modality": "llm",
                "source": "sagemaker",
                "uri": "sagemaker/meta-textgeneration-llama-2-7b",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "sagemaker/meta-textgeneration-llama-2-7b-f",
                "modality": "llm",
                "source": "sagemaker",
                "uri": "sagemaker/meta-textgeneration-llama-2-7b-f",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "sagemaker/meta-textgeneration-llama-2-13b",
                "modality": "llm",
                "source": "sagemaker",
                "uri": "sagemaker/meta-textgeneration-llama-2-13b",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "sagemaker/meta-textgeneration-llama-2-13b-f",
                "modality": "llm",
                "source": "sagemaker",
                "uri": "sagemaker/meta-textgeneration-llama-2-13b-f",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "sagemaker/meta-textgeneration-llama-2-70b",
                "modality": "llm",
                "source": "sagemaker",
                "uri": "sagemaker/meta-textgeneration-llama-2-70b",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "sagemaker/meta-textgeneration-llama-2-70b-b-f",
                "modality": "llm",
                "source": "sagemaker",
                "uri": "sagemaker/meta-textgeneration-llama-2-70b-b-f",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            }
        ]
    },
    "together_ai": {
        "models": [
            {
                "name": "together-ai-up-to-4b",
                "modality": "llm",
                "source": "together_ai",
                "uri": "together-ai-up-to-4b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1e-07
                }
            },
            {
                "name": "together-ai-4.1b-8b",
                "modality": "llm",
                "source": "together_ai",
                "uri": "together-ai-4.1b-8b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "together-ai-8.1b-21b",
                "modality": "llm",
                "source": "together_ai",
                "uri": "together-ai-8.1b-21b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 3e-07
                }
            },
            {
                "name": "together-ai-21.1b-41b",
                "modality": "llm",
                "source": "together_ai",
                "uri": "together-ai-21.1b-41b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 8e-07
                },
                "output_cost": {
                    "output_cost_per_token": 8e-07
                }
            },
            {
                "name": "together-ai-41.1b-80b",
                "modality": "llm",
                "source": "together_ai",
                "uri": "together-ai-41.1b-80b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9e-07
                }
            },
            {
                "name": "together-ai-81.1b-110b",
                "modality": "llm",
                "source": "together_ai",
                "uri": "together-ai-81.1b-110b",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.8e-06
                }
            },
            {
                "name": "together-ai-embedding-up-to-150m",
                "modality": "embedding",
                "source": "together_ai",
                "uri": "together-ai-embedding-up-to-150m",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 8e-09
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "together-ai-embedding-151m-to-350m",
                "modality": "embedding",
                "source": "together_ai",
                "uri": "together-ai-embedding-151m-to-350m",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 1.6e-08
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1",
                "modality": "llm",
                "source": "together_ai",
                "uri": "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": 6e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "together_ai/mistralai/Mistral-7B-Instruct-v0.1",
                "modality": "llm",
                "source": "together_ai",
                "uri": "together_ai/mistralai/Mistral-7B-Instruct-v0.1",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            },
            {
                "name": "together_ai/togethercomputer/CodeLlama-34b-Instruct",
                "modality": "llm",
                "source": "together_ai",
                "uri": "together_ai/togethercomputer/CodeLlama-34b-Instruct",
                "max_input_tokens": null,
                "input_cost": {
                    "input_cost_per_token": null
                },
                "output_cost": {
                    "output_cost_per_token": null
                }
            }
        ]
    },
    "deepinfra": {
        "models": [
            {
                "name": "deepinfra/lizpreciatior/lzlv_70b_fp16_hf",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/lizpreciatior/lzlv_70b_fp16_hf",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9e-07
                }
            },
            {
                "name": "deepinfra/Gryphe/MythoMax-L2-13b",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/Gryphe/MythoMax-L2-13b",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 2.2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.2e-07
                }
            },
            {
                "name": "deepinfra/mistralai/Mistral-7B-Instruct-v0.1",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/mistralai/Mistral-7B-Instruct-v0.1",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 1.3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.3e-07
                }
            },
            {
                "name": "deepinfra/meta-llama/Llama-2-70b-chat-hf",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/meta-llama/Llama-2-70b-chat-hf",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9e-07
                }
            },
            {
                "name": "deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 2.7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.7e-07
                }
            },
            {
                "name": "deepinfra/codellama/CodeLlama-34b-Instruct-hf",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/codellama/CodeLlama-34b-Instruct-hf",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 6e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "deepinfra/deepinfra/mixtral",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/deepinfra/mixtral",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 2.7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.7e-07
                }
            },
            {
                "name": "deepinfra/Phind/Phind-CodeLlama-34B-v2",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/Phind/Phind-CodeLlama-34B-v2",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 6e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 2.7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.7e-07
                }
            },
            {
                "name": "deepinfra/deepinfra/airoboros-70b",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/deepinfra/airoboros-70b",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9e-07
                }
            },
            {
                "name": "deepinfra/01-ai/Yi-34B-Chat",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/01-ai/Yi-34B-Chat",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 6e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "deepinfra/01-ai/Yi-6B-200K",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/01-ai/Yi-6B-200K",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 1.3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.3e-07
                }
            },
            {
                "name": "deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9e-07
                }
            },
            {
                "name": "deepinfra/meta-llama/Llama-2-13b-chat-hf",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/meta-llama/Llama-2-13b-chat-hf",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 2.2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.2e-07
                }
            },
            {
                "name": "deepinfra/amazon/MistralLite",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/amazon/MistralLite",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "deepinfra/meta-llama/Llama-2-7b-chat-hf",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/meta-llama/Llama-2-7b-chat-hf",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1.3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.3e-07
                }
            },
            {
                "name": "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 8e-08
                },
                "output_cost": {
                    "output_cost_per_token": 8e-08
                }
            },
            {
                "name": "deepinfra/meta-llama/Meta-Llama-3-70B-Instruct",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/meta-llama/Meta-Llama-3-70B-Instruct",
                "max_input_tokens": 8191,
                "input_cost": {
                    "input_cost_per_token": 5.9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 7.9e-07
                }
            },
            {
                "name": "deepinfra/01-ai/Yi-34B-200K",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/01-ai/Yi-34B-200K",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 6e-07
                },
                "output_cost": {
                    "output_cost_per_token": 6e-07
                }
            },
            {
                "name": "deepinfra/openchat/openchat_3.5",
                "modality": "llm",
                "source": "deepinfra",
                "uri": "deepinfra/openchat/openchat_3.5",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1.3e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.3e-07
                }
            }
        ]
    },
    "perplexity": {
        "models": [
            {
                "name": "perplexity/codellama-34b-instruct",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/codellama-34b-instruct",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 3.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.4e-06
                }
            },
            {
                "name": "perplexity/codellama-70b-instruct",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/codellama-70b-instruct",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-06
                }
            },
            {
                "name": "perplexity/llama-3.1-70b-instruct",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/llama-3.1-70b-instruct",
                "max_input_tokens": 131072,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-06
                }
            },
            {
                "name": "perplexity/llama-3.1-8b-instruct",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/llama-3.1-8b-instruct",
                "max_input_tokens": 131072,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "perplexity/llama-3.1-sonar-huge-128k-online",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/llama-3.1-sonar-huge-128k-online",
                "max_input_tokens": 127072,
                "input_cost": {
                    "input_cost_per_token": 5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 5e-06
                }
            },
            {
                "name": "perplexity/llama-3.1-sonar-large-128k-online",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/llama-3.1-sonar-large-128k-online",
                "max_input_tokens": 127072,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-06
                }
            },
            {
                "name": "perplexity/llama-3.1-sonar-large-128k-chat",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/llama-3.1-sonar-large-128k-chat",
                "max_input_tokens": 131072,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-06
                }
            },
            {
                "name": "perplexity/llama-3.1-sonar-small-128k-chat",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/llama-3.1-sonar-small-128k-chat",
                "max_input_tokens": 131072,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "perplexity/llama-3.1-sonar-small-128k-online",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/llama-3.1-sonar-small-128k-online",
                "max_input_tokens": 127072,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "perplexity/pplx-7b-chat",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/pplx-7b-chat",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 7e-08
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-07
                }
            },
            {
                "name": "perplexity/pplx-70b-chat",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/pplx-70b-chat",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-06
                }
            },
            {
                "name": "perplexity/pplx-7b-online",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/pplx-7b-online",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-07
                }
            },
            {
                "name": "perplexity/pplx-70b-online",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/pplx-70b-online",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 0.0
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-06
                }
            },
            {
                "name": "perplexity/llama-2-70b-chat",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/llama-2-70b-chat",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 7e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-06
                }
            },
            {
                "name": "perplexity/mistral-7b-instruct",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/mistral-7b-instruct",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 7e-08
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-07
                }
            },
            {
                "name": "perplexity/mixtral-8x7b-instruct",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/mixtral-8x7b-instruct",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 7e-08
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-07
                }
            },
            {
                "name": "perplexity/sonar-small-chat",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/sonar-small-chat",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 7e-08
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-07
                }
            },
            {
                "name": "perplexity/sonar-small-online",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/sonar-small-online",
                "max_input_tokens": 12000,
                "input_cost": {
                    "input_cost_per_token": 0
                },
                "output_cost": {
                    "output_cost_per_token": 2.8e-07
                }
            },
            {
                "name": "perplexity/sonar-medium-chat",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/sonar-medium-chat",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 6e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.8e-06
                }
            },
            {
                "name": "perplexity/sonar-medium-online",
                "modality": "llm",
                "source": "perplexity",
                "uri": "perplexity/sonar-medium-online",
                "max_input_tokens": 12000,
                "input_cost": {
                    "input_cost_per_token": 0
                },
                "output_cost": {
                    "output_cost_per_token": 1.8e-06
                }
            }
        ]
    },
    "fireworks_ai": {
        "models": [
            {
                "name": "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct",
                "modality": "llm",
                "source": "fireworks_ai",
                "uri": "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1e-07
                }
            },
            {
                "name": "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct",
                "modality": "llm",
                "source": "fireworks_ai",
                "uri": "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1e-07
                }
            },
            {
                "name": "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
                "modality": "llm",
                "source": "fireworks_ai",
                "uri": "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2e-07
                }
            },
            {
                "name": "accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
                "modality": "llm",
                "source": "fireworks_ai",
                "uri": "accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9e-07
                }
            },
            {
                "name": "fireworks_ai/accounts/fireworks/models/firefunction-v2",
                "modality": "llm",
                "source": "fireworks_ai",
                "uri": "fireworks_ai/accounts/fireworks/models/firefunction-v2",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9e-07
                }
            },
            {
                "name": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf",
                "modality": "llm",
                "source": "fireworks_ai",
                "uri": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf",
                "max_input_tokens": 65536,
                "input_cost": {
                    "input_cost_per_token": 1.2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.2e-06
                }
            },
            {
                "name": "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct",
                "modality": "llm",
                "source": "fireworks_ai",
                "uri": "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9e-07
                }
            },
            {
                "name": "fireworks_ai/accounts/fireworks/models/yi-large",
                "modality": "llm",
                "source": "fireworks_ai",
                "uri": "fireworks_ai/accounts/fireworks/models/yi-large",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 3e-06
                }
            },
            {
                "name": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct",
                "modality": "llm",
                "source": "fireworks_ai",
                "uri": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct",
                "max_input_tokens": 65536,
                "input_cost": {
                    "input_cost_per_token": 1.2e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.2e-06
                }
            }
        ]
    },
    "anyscale": {
        "models": [
            {
                "name": "anyscale/mistralai/Mistral-7B-Instruct-v0.1",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/mistralai/Mistral-7B-Instruct-v0.1",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-07
                }
            },
            {
                "name": "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-07
                }
            },
            {
                "name": "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1",
                "max_input_tokens": 65536,
                "input_cost": {
                    "input_cost_per_token": 9e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9e-07
                }
            },
            {
                "name": "anyscale/HuggingFaceH4/zephyr-7b-beta",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/HuggingFaceH4/zephyr-7b-beta",
                "max_input_tokens": 16384,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-07
                }
            },
            {
                "name": "anyscale/google/gemma-7b-it",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/google/gemma-7b-it",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-07
                }
            },
            {
                "name": "anyscale/meta-llama/Llama-2-7b-chat-hf",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/meta-llama/Llama-2-7b-chat-hf",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-07
                }
            },
            {
                "name": "anyscale/meta-llama/Llama-2-13b-chat-hf",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/meta-llama/Llama-2-13b-chat-hf",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.5e-07
                }
            },
            {
                "name": "anyscale/meta-llama/Llama-2-70b-chat-hf",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/meta-llama/Llama-2-70b-chat-hf",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-06
                }
            },
            {
                "name": "anyscale/codellama/CodeLlama-34b-Instruct-hf",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/codellama/CodeLlama-34b-Instruct-hf",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-06
                }
            },
            {
                "name": "anyscale/codellama/CodeLlama-70b-Instruct-hf",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/codellama/CodeLlama-70b-Instruct-hf",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-06
                }
            },
            {
                "name": "anyscale/meta-llama/Meta-Llama-3-8B-Instruct",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/meta-llama/Meta-Llama-3-8B-Instruct",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-07
                }
            },
            {
                "name": "anyscale/meta-llama/Meta-Llama-3-70B-Instruct",
                "modality": "llm",
                "source": "anyscale",
                "uri": "anyscale/meta-llama/Meta-Llama-3-70B-Instruct",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1e-06
                }
            }
        ]
    },
    "cloudflare": {
        "models": [
            {
                "name": "cloudflare/@cf/meta/llama-2-7b-chat-fp16",
                "modality": "llm",
                "source": "cloudflare",
                "uri": "cloudflare/@cf/meta/llama-2-7b-chat-fp16",
                "max_input_tokens": 3072,
                "input_cost": {
                    "input_cost_per_token": 1.923e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.923e-06
                }
            },
            {
                "name": "cloudflare/@cf/meta/llama-2-7b-chat-int8",
                "modality": "llm",
                "source": "cloudflare",
                "uri": "cloudflare/@cf/meta/llama-2-7b-chat-int8",
                "max_input_tokens": 2048,
                "input_cost": {
                    "input_cost_per_token": 1.923e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.923e-06
                }
            },
            {
                "name": "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1",
                "modality": "llm",
                "source": "cloudflare",
                "uri": "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.923e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.923e-06
                }
            },
            {
                "name": "cloudflare/@hf/thebloke/codellama-7b-instruct-awq",
                "modality": "llm",
                "source": "cloudflare",
                "uri": "cloudflare/@hf/thebloke/codellama-7b-instruct-awq",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1.923e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.923e-06
                }
            }
        ]
    },
    "voyage": {
        "models": [
            {
                "name": "voyage/voyage-01",
                "modality": "embedding",
                "source": "voyage",
                "uri": "voyage/voyage-01",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "voyage/voyage-lite-01",
                "modality": "embedding",
                "source": "voyage",
                "uri": "voyage/voyage-lite-01",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "voyage/voyage-large-2",
                "modality": "embedding",
                "source": "voyage",
                "uri": "voyage/voyage-large-2",
                "max_input_tokens": 16000,
                "input_cost": {
                    "input_cost_per_token": 1.2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "voyage/voyage-law-2",
                "modality": "embedding",
                "source": "voyage",
                "uri": "voyage/voyage-law-2",
                "max_input_tokens": 16000,
                "input_cost": {
                    "input_cost_per_token": 1.2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "voyage/voyage-code-2",
                "modality": "embedding",
                "source": "voyage",
                "uri": "voyage/voyage-code-2",
                "max_input_tokens": 16000,
                "input_cost": {
                    "input_cost_per_token": 1.2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "voyage/voyage-2",
                "modality": "embedding",
                "source": "voyage",
                "uri": "voyage/voyage-2",
                "max_input_tokens": 4000,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "voyage/voyage-lite-02-instruct",
                "modality": "embedding",
                "source": "voyage",
                "uri": "voyage/voyage-lite-02-instruct",
                "max_input_tokens": 4000,
                "input_cost": {
                    "input_cost_per_token": 1e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "voyage/voyage-finance-2",
                "modality": "embedding",
                "source": "voyage",
                "uri": "voyage/voyage-finance-2",
                "max_input_tokens": 32000,
                "input_cost": {
                    "input_cost_per_token": 1.2e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            }
        ]
    },
    "databricks": {
        "models": [
            {
                "name": "databricks/databricks-meta-llama-3-1-405b-instruct",
                "modality": "llm",
                "source": "databricks",
                "uri": "databricks/databricks-meta-llama-3-1-405b-instruct",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 5e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.500002e-05
                }
            },
            {
                "name": "databricks/databricks-meta-llama-3-1-70b-instruct",
                "modality": "llm",
                "source": "databricks",
                "uri": "databricks/databricks-meta-llama-3-1-70b-instruct",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.00002e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.99999e-06
                }
            },
            {
                "name": "databricks/databricks-dbrx-instruct",
                "modality": "llm",
                "source": "databricks",
                "uri": "databricks/databricks-dbrx-instruct",
                "max_input_tokens": 32768,
                "input_cost": {
                    "input_cost_per_token": 7.4998e-07
                },
                "output_cost": {
                    "output_cost_per_token": 2.24901e-06
                }
            },
            {
                "name": "databricks/databricks-meta-llama-3-70b-instruct",
                "modality": "llm",
                "source": "databricks",
                "uri": "databricks/databricks-meta-llama-3-70b-instruct",
                "max_input_tokens": 128000,
                "input_cost": {
                    "input_cost_per_token": 1.00002e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.99999e-06
                }
            },
            {
                "name": "databricks/databricks-llama-2-70b-chat",
                "modality": "llm",
                "source": "databricks",
                "uri": "databricks/databricks-llama-2-70b-chat",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 5.0001e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-06
                }
            },
            {
                "name": "databricks/databricks-mixtral-8x7b-instruct",
                "modality": "llm",
                "source": "databricks",
                "uri": "databricks/databricks-mixtral-8x7b-instruct",
                "max_input_tokens": 4096,
                "input_cost": {
                    "input_cost_per_token": 5.0001e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9.9902e-07
                }
            },
            {
                "name": "databricks/databricks-mpt-30b-instruct",
                "modality": "llm",
                "source": "databricks",
                "uri": "databricks/databricks-mpt-30b-instruct",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 9.9902e-07
                },
                "output_cost": {
                    "output_cost_per_token": 9.9902e-07
                }
            },
            {
                "name": "databricks/databricks-mpt-7b-instruct",
                "modality": "llm",
                "source": "databricks",
                "uri": "databricks/databricks-mpt-7b-instruct",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 5.0001e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "databricks/databricks-bge-large-en",
                "modality": "embedding",
                "source": "databricks",
                "uri": "databricks/databricks-bge-large-en",
                "max_input_tokens": 512,
                "input_cost": {
                    "input_cost_per_token": 1.0003e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            },
            {
                "name": "databricks/databricks-gte-large-en",
                "modality": "embedding",
                "source": "databricks",
                "uri": "databricks/databricks-gte-large-en",
                "max_input_tokens": 8192,
                "input_cost": {
                    "input_cost_per_token": 1.2999e-07
                },
                "output_cost": {
                    "output_cost_per_token": 0.0
                }
            }
        ]
    },
    "anthropic": {
        "models": [
            {
                "name": "claude-3-5-sonnet-20240620",
                "modality": "llm",
                "source": "anthropic",
                "uri": "claude-3-5-sonnet-20240620",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "claude-3-haiku-20240307",
                "modality": "llm",
                "source": "anthropic",
                "uri": "claude-3-haiku-20240307",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 2.5e-07
                },
                "output_cost": {
                    "output_cost_per_token": 1.25e-06
                }
            },
            {
                "name": "claude-3-opus-20240229",
                "modality": "llm",
                "source": "anthropic",
                "uri": "claude-3-opus-20240229",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 1.5e-05
                },
                "output_cost": {
                    "output_cost_per_token": 7.5e-05
                }
            },
            {
                "name": "claude-3-5-sonnet-20240620",
                "modality": "llm",
                "source": "anthropic",
                "uri": "claude-3-5-sonnet-20240620",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "claude-3-sonnet-20240229",
                "modality": "llm",
                "source": "anthropic",
                "uri": "claude-3-sonnet-20240229",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 3e-06
                },
                "output_cost": {
                    "output_cost_per_token": 1.5e-05
                }
            },
            {
                "name": "claude-2.1",
                "modality": "llm",
                "source": "anthropic",
                "uri": "claude-2.1",
                "max_input_tokens": 200000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            },
            {
                "name": "claude-2",
                "modality": "llm",
                "source": "anthropic",
                "uri": "claude-2",
                "max_input_tokens": 100000,
                "input_cost": {
                    "input_cost_per_token": 8e-06
                },
                "output_cost": {
                    "output_cost_per_token": 2.4e-05
                }
            }
        ]
    }
}